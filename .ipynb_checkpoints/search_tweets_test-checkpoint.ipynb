{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n",
      "{\"errors\":[{\"code\":99,\"message\":\"Unable to verify your credentials\",\"label\":\"authenticity_token_error\"}]}\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://api.twitter.com/oauth2/token",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8d95c6568655>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# opening the communication\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m premium_search_args = load_credentials(\"twitter_keys.yaml\",\n\u001b[0m\u001b[0;32m     53\u001b[0m                                        \u001b[0myaml_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"search_tweets_api\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                                        env_overwrite=False)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\searchtweets\\credentials.py\u001b[0m in \u001b[0;36mload_credentials\u001b[1;34m(filename, account_type, yaml_key, env_overwrite)\u001b[0m\n\u001b[0;32m    187\u001b[0m                    \u001b[1;32mif\u001b[0m \u001b[0menv_overwrite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                    else merge_dicts(env_vars, yaml_vars))\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[0mparsed_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_credentials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccount_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccount_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparsed_vars\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\searchtweets\\credentials.py\u001b[0m in \u001b[0;36m_parse_credentials\u001b[1;34m(search_creds, account_type)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"consumer_key\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msearch_creds\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                   \u001b[1;32mand\u001b[0m \u001b[1;34m\"consumer_secret\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msearch_creds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                     search_creds[\"bearer_token\"] = _generate_bearer_token(\n\u001b[0m\u001b[0;32m     90\u001b[0m                         \u001b[0msearch_creds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"consumer_key\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                         search_creds[\"consumer_secret\"])\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\searchtweets\\credentials.py\u001b[0m in \u001b[0;36m_generate_bearer_token\u001b[1;34m(consumer_key, consumer_secret)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m400\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'access_token'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://api.twitter.com/oauth2/token"
     ]
    }
   ],
   "source": [
    "# https://lucahammer.com/2019/11/05/collecting-old-tweets-with-the-twitter-premium-api-and-python/\n",
    "# https://twitterdev.github.io/search-tweets-python/\n",
    "# https://github.com/twitterdev/search-tweets-python/tree/master/examples\n",
    "'''\n",
    "Example script to collect old Tweets with the Twitter Premium Search API\n",
    "Article: https://lucahammer.com/?p=350\n",
    "\n",
    "To use this script, change the constants (UPPERCASE variables) to your needs,\n",
    "and run it. For example in your CLI by executing: \"python premiumapi.py\".\n",
    "\n",
    "Find your app credentials here: https://developer.twitter.com/en/apps\n",
    "Find your dev environment label here: https://developer.twitter.com/en/account/environments\n",
    "'''\n",
    "# Variables used to be able to pull the data needed from twitter\n",
    "API_SCOPE = 'fullarchive'\n",
    "DEV_ENVIRONMENT_LABEL = 'injuries'\n",
    "SEARCH_QUERY = 'from:InsideInjuries Christian McCaffrey Shoulder'\n",
    "RESULTS_PER_CALL = 100  # 100 for sandbox, 500 for paid tiers\n",
    "TO_DATE = '2020-11-15' # format YYYY-MM-DD HH:MM (hour and minutes optional)\n",
    "FROM_DATE = '2020-11-1'  # format YYYY-MM-DD HH:MM (hour and minutes optional)\n",
    "\n",
    "# max number of tweets to collect\n",
    "MAX_RESULTS = 3\n",
    "\n",
    "# create csv\n",
    "FILENAME = 'twitter_nfl_injury.csv'  # Where the Tweets should be saved\n",
    "\n",
    "# Script prints an update to the CLI every time it collected another X Tweets\n",
    "PRINT_AFTER_X = 1\n",
    "\n",
    "#create a yaml document to hold credentials\n",
    "# import yaml\n",
    "# config = dict(\n",
    "#     search_tweets_api=dict(\n",
    "#         account_type='premium',\n",
    "#         endpoint=f\"https://api.twitter.com/1.1/tweets/search/{API_SCOPE}/{DEV_ENVIRONMENT_LABEL}.json\",\n",
    "#         consumer_key='API',\n",
    "#         consumer_secret='API_Secret'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "with open('twitter_keys.yaml', 'w') as config_file:\n",
    "    yaml.dump(config, config_file, default_flow_style=False)\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from searchtweets import load_credentials, gen_rule_payload, ResultStream\n",
    "\n",
    "# opening the communication\n",
    "premium_search_args = load_credentials(\"twitter_keys.yaml\",\n",
    "                                       yaml_key=\"search_tweets_api\",\n",
    "                                       env_overwrite=False)\n",
    "\n",
    "# creating the payload for search\n",
    "rule = gen_rule_payload(SEARCH_QUERY,\n",
    "                        results_per_call=RESULTS_PER_CALL,\n",
    "                        from_date=FROM_DATE,\n",
    "                        to_date=TO_DATE\n",
    "                        )\n",
    "\n",
    "#returning the results from the payload and stops at max_results\n",
    "rs = ResultStream(rule_payload=rule,\n",
    "                  max_results=MAX_RESULTS,\n",
    "                  **premium_search_args)\n",
    "\n",
    "# working properly, need to filter out retweets by using retweeted_status to remove retweets would be easiest in a dataframe\n",
    "# need to format it for a pandas DF and write into csv instead of writing the full dictionary\n",
    "# find headers within the data so that the differing size rows get split up properly\n",
    "\n",
    "# loop to open FILENAME as f and write to f the value of tweet which would be results_per_call\n",
    "with open(FILENAME, 'a', encoding='utf-8') as f:\n",
    "    n = 0\n",
    "    for tweet in rs.stream():\n",
    "        n += 1\n",
    "        # once n reaches value of print_after_x function discontinues\n",
    "        if n % PRINT_AFTER_X == 0:\n",
    "            print('{0}: {1}'.format(str(n), tweet['created_at']))\n",
    "        print(tweet)\n",
    "        #df = pd.DataFrame.from_dict(tweet)\n",
    "        # writing tweets to file\n",
    "        json.dump(tweet, f)\n",
    "        f.write('\\n')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
