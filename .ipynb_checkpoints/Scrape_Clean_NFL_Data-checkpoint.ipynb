{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash, requests, os\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import date, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def team_data_scrape(Start_Year,End_Year,url):\n",
    "    page = 0\n",
    "    stat_login_url = \"https://stathead.com/users/login.cgi\"\n",
    "    stat_user_name = os.environ.get('statheadusername')\n",
    "    stat_password = os.environ.get('statheadpassword')\n",
    "    stat_payload = {\n",
    "        'username': stat_user_name,\n",
    "        'password': stat_password\n",
    "    }\n",
    "    \n",
    "    if url == 1:\n",
    "        stat_url = 'https://stathead.com/football/tgl_finder.cgi?request=1&temperature_gtlt=lt&game_num_max=99&week_num_max=99&order_by=points&match=game&year_max={End_Year}&order_by_asc=0&week_num_min=0&game_type=E&game_num_min=0&year_min={Start_Year}&cstat[1]=all_td_team&ccomp[1]=gt&cval[1]=0&cstat[2]=third_down_att&ccomp[2]=gt&cval[2]=0&cstat[3]=vegas_line&ccomp[3]=gt&cval[3]=-50&cstat[4]=penalties&ccomp[4]=gt&cval[4]=0&cstat[5]=rush_att&ccomp[5]=gt&cval[5]=0&cstat[6]=tot_yds&ccomp[6]=gt&cval[6]=0&cstat[7]=first_down&ccomp[7]=gt&cval[7]=0&cstat[8]=punt&ccomp[8]=gt&cval[8]=0&cstat[9]=pass_cmp&ccomp[9]=gt&cval[9]=0&offset={page}'\n",
    "    elif url == 2:\n",
    "        stat_url = 'https://stathead.com/football/tgl_finder.cgi?request=1&temperature_gtlt=lt&game_num_max=99&week_num_max=99&order_by=all_td_opp&match=game&year_max={End_Year}&order_by_asc=0&week_num_min=0&game_type=R&game_num_min=0&year_min={Start_Year}&cstat[1]=tot_yds_opp&ccomp[1]=gt&cval[1]=0&cstat[2]=rush_yds_diff&ccomp[2]=gt&cval[2]=-500&cstat[3]=score_diff_thru_1&ccomp[3]=gt&cval[3]=-500&cstat[4]=rush_att_opp&ccomp[4]=gt&cval[4]=0&cstat[5]=kick_ret_td_tgl&ccomp[5]=gt&cval[5]=0&cstat[6]=pass_cmp_opp&ccomp[6]=gt&cval[6]=0&cstat[7]=first_down_opp&ccomp[7]=gt&cval[7]=0&cstat[8]=score_diff_1_qtr&ccomp[8]=gt&cval[8]=-500&cstat[9]=third_down_att_opp&ccomp[9]=gt&cval[9]=0&offset={page}'\n",
    "    elif url != 1 or 2:\n",
    "        print(\"Please select 1 or 2.\")\n",
    "        \n",
    "    with requests.Session() as session:\n",
    "        \n",
    "        s = session.post(stat_login_url, data=stat_payload)\n",
    "        \n",
    "        while page < 100000:\n",
    "            \n",
    "            website = session.get(stat_url.format(Start_Year=Start_Year,End_Year=End_Year,page=page)).text\n",
    "            soup = BeautifulSoup(website, 'html')\n",
    "            table = soup.find('table', attrs={'class': 'sortable', 'id': 'results'})\n",
    "\n",
    "            table_headers = [header.text for header in table.find('thead').find_all('th')]\n",
    "            table_rows = table.find_all('tr')\n",
    "\n",
    "            final_data = []\n",
    "            \n",
    "            for tr in table_rows:\n",
    "                td = tr.find_all('td')\n",
    "                row = [tr.text for tr in td]\n",
    "                final_data.append(row)\n",
    "                \n",
    "            df = pd.DataFrame(final_data[1:], columns=table_headers[12:])\n",
    "            \n",
    "            print(page)\n",
    "            \n",
    "            if url == 1:\n",
    "                df.to_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\nflteam_data_1_{Start_Year}_{End_Year}_raw.csv',mode='a',index=False)\n",
    "            else:\n",
    "                df.to_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\nflteam_data_2_{Start_Year}_{End_Year}_raw.csv',mode='a',index=False)\n",
    "\n",
    "            page += 100\n",
    "                \n",
    "        print('Done')\n",
    "        print(page)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def player_snap_scrape(Start_Year,End_Year):\n",
    "    \n",
    "    sides = ['','defense.php']\n",
    "    weeks = []\n",
    "    for wk in range(1,18):\n",
    "        weeks.append(wk)\n",
    "\n",
    "    ENDPOINT = \"https://www.fantasypros.com/nfl/reports/snap-count-analysis/{side}?year={year}&week={week}&snaps=0&range=week\"\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    for year in range(Start_Year, End_Year+1):\n",
    "\n",
    "        for side in sides:\n",
    "\n",
    "            for week in weeks:\n",
    "\n",
    "                res = requests.get(ENDPOINT.format(year=year,side=side,week=week))\n",
    "\n",
    "                soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "                table = soup.find('table', {'id': 'data'})\n",
    "                table_headers = [header.text for header in table.find('thead').find_all('th')]\n",
    "                table_rows = table.find_all('tr')\n",
    "\n",
    "                final_data = []\n",
    "\n",
    "                for tr in table_rows:\n",
    "                    td = tr.find_all('td')\n",
    "                    row = [tr.text for tr in td]\n",
    "                    final_data.append(row)\n",
    "\n",
    "                df = pd.DataFrame(final_data[1:], columns=table_headers)\n",
    "                df['Year'] = year\n",
    "                df['Week'] = week\n",
    "                #print(side,year,week)\n",
    "\n",
    "                final_df = pd.concat([final_df, df])\n",
    "\n",
    "    final_df.to_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\snapcounts_{Start_Year}_{End_Year}_raw.csv',index=False)\n",
    "    print('Done')\n",
    "    \n",
    "    \n",
    "    \n",
    "def injury_reports_scrape(Start_Year,End_Year):\n",
    "    \n",
    "    teams = ['crd', 'atl', 'rav', 'buf', 'car', 'chi', 'cin', 'cle', 'dal', 'den', 'det', 'gnb','htx','clt','jax','kan',\n",
    "             'sdg','ram','mia','min','nor','nwe','nyg','nyj','rai','phi','pit','sea','sfo','tam','oti','was']\n",
    "\n",
    "    ENDPOINT = 'https://www.pro-football-reference.com/teams/{team}/{year}_injuries.htm'\n",
    "\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    for year in range(Start_Year, End_Year+1):\n",
    "\n",
    "        for team in teams:\n",
    "\n",
    "            res = requests.get(ENDPOINT.format(year=year,team=team))\n",
    "\n",
    "            soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "            table = soup.find('table', attrs={'class': 'sortable', 'id': 'team_injuries'})\n",
    "            table_rows = table.find_all('tr')\n",
    "\n",
    "            final_data = []\n",
    "            for tr in table_rows:\n",
    "                td = tr.find_all(['th','td'])\n",
    "                row = [tr['data-tip'] if tr.has_attr(\"data-tip\") else tr.text for tr in td]\n",
    "                final_data.append(row)\n",
    "\n",
    "            dfdata = final_data[1:]\n",
    "            data_body = [[dfdata[j][i] for j in range(len(dfdata))] for i in range(len(dfdata[0]))]\n",
    "\n",
    "            df = pd.DataFrame(data_body,final_data[0]).T\n",
    "\n",
    "            df.insert(loc=1,column='Team',value=team)\n",
    "            df.insert(loc=2,column='Year',value=year)\n",
    "\n",
    "            final_df = pd.concat([final_df, df])\n",
    "            final_df.rename(columns={'PlayerÂ ':'Player'},inplace=True)\n",
    "            print(team,year)\n",
    "\n",
    "    final_df.to_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\nfl_injuryreport_{Start_Year}_{End_Year}_raw.csv',index=False)\n",
    "    print('Done')    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def player_stats_scape(Start_Year,End_Year):\n",
    "    page = 0\n",
    "    location = 5000\n",
    "    stat_login_url = \"https://stathead.com/users/login.cgi\"\n",
    "    stat_user_name = os.environ.get('statheadusername')\n",
    "    stat_password = os.environ.get('statheadpassword')\n",
    "    stat_payload = {\n",
    "        'username': stat_user_name,\n",
    "        'password': stat_password\n",
    "    }\n",
    "    stat_url = \"https://stathead.com/football/pgl_finder.cgi?request=1&game_num_max=99&week_num_max=99&order_by=all_td&season_start=1&qb_gwd=0&order_by_asc=0&qb_comeback=0&week_num_min=0&game_num_min=0&year_min={Start_Year}&match=game&year_max={End_Year}&season_end=-1&age_min=0&game_type=R&age_max=99&positions[]=qb&positions[]=rb&positions[]=wr&positions[]=te&positions[]=e&positions[]=t&positions[]=g&positions[]=c&positions[]=ol&positions[]=dt&positions[]=de&positions[]=dl&positions[]=ilb&positions[]=olb&positions[]=lb&positions[]=cb&positions[]=s&positions[]=db&positions[]=k&positions[]=p&cstat[1]=punt_ret&ccomp[1]=gt&cval[1]=0&cstat[2]=sacks&ccomp[2]=gt&cval[2]=0&cstat[3]=fumbles&ccomp[3]=gt&cval[3]=0&cstat[4]=rush_att&ccomp[4]=gt&cval[4]=0&cstat[5]=pass_defended&ccomp[5]=gt&cval[5]=0&cstat[6]=pass_cmp&ccomp[6]=gt&cval[6]=0&cstat[7]=targets&ccomp[7]=gt&cval[7]=0&cstat[8]=kick_ret&ccomp[8]=gt&cval[8]=0&offset={page}\"\n",
    "    \n",
    "    with requests.Session() as session:\n",
    "        \n",
    "        s = session.post(stat_login_url, data=stat_payload)\n",
    "        \n",
    "        while page < 100000:\n",
    "            \n",
    "            website = session.get(stat_url.format(Start_Year=Start_Year,End_Year=End_Year,page=page)).text\n",
    "            soup = BeautifulSoup(website, 'html')\n",
    "            table = soup.find('table', attrs={'class': 'sortable', 'id': 'results'})\n",
    "\n",
    "            table_headers = [header.text for header in table.find('thead').find_all('th')]\n",
    "            table_rows = table.find_all('tr')\n",
    "\n",
    "            final_data = []\n",
    "            \n",
    "            for tr in table_rows:\n",
    "                td = tr.find_all('td')\n",
    "                row = [tr.text for tr in td]\n",
    "                final_data.append(row)\n",
    "                \n",
    "            df = pd.DataFrame(final_data[1:], columns=table_headers[11:])\n",
    "            df.to_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\player_stats_{Start_Year}_{End_Year}_raw.csv',mode='a',index=False)\n",
    "\n",
    "            if page > location:\n",
    "                print(page)\n",
    "                location += 5000\n",
    "                \n",
    "            page += 100\n",
    "            \n",
    "        print('Done')\n",
    "        print(page)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "def data_clean(Start_Year,End_Year):\n",
    "    \n",
    "    snaps = pd.read_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\snapcounts_{Start_Year}_{End_Year}.csv')\n",
    "    snaps.drop(['Fantasy Pts','Pts/100 Snaps','Snap %','Rush %','Tgt %','Touch %','Util %','Tackle %','Sack %','QB Hit %','Snaps/Gm'],axis=1,inplace=True)\n",
    "    snaps['Year'] = snaps['Year'].astype(str)\n",
    "    snaps['Week'] = snaps['Week'].astype(str)\n",
    "    snaps.replace({'Team':{'FA':'','GB':'GNB','JAC':'JAX','KC':'KAN','NE':'NWE','NO':'NOR','SF':'SFO','TB':'TAM'}},inplace=True)\n",
    "    snaps['Player'] = snaps['Player']+' '\n",
    "    snaps.replace({'Player':{' Jr. ':'',' Jr ':'',' Sr. ':'',' Sr ':'',' III ':'',' II ':'',' IV ':'',' V ':''}},regex=True,inplace=True)\n",
    "    snaps['Player'] = snaps['Player'].str.strip(' ')\n",
    "\n",
    "    print('Snaps data cleaned.')\n",
    "\n",
    "    stats = pd.read_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\player_stats_{Start_Year}_{End_Year}.csv')\n",
    "    stats.dropna(how='all',inplace=True)\n",
    "    stats.drop(stats[stats['Player'] == 'Player'].index, inplace = True)\n",
    "    stats.drop('Lg',axis=1,inplace=True)\n",
    "    stats.rename(columns={'Tm':'Team','Unnamed: 6':'Away_Home','Cmp':'IPass_Cmp','Att':'IPass_Att','Cmp%':'IPass_Cmp%','Yds':'IPass_Yds',\\\n",
    "                 'TD':'IPass_TD','Int':'IPass_Int','Rate':'IQB_Rate','Sk':'I_Sk','Yds.1':'ISk_Yds','Y/A':'IPass_Y/A',\\\n",
    "                 'AY/A':'IPass_AdjY/A','Att.1':'IRush_Att','Yds.2':'IRush_Yds','Y/A.1':'IRush_Y/A','TD.1':'IRush_TD',\\\n",
    "                 'Tgt':'IRec_Tgt','Rec':'IRec_Rec','Yds.3':'IRec_Yds','Y/R':'IRec_Y/R','TD.2':'IRec_TD','Ctch%':'IRec_Ctch%',\\\n",
    "                 'Y/Tgt':'IRec_Y/Tgt','XPM':'IXP_Made','XPA':'IXP_Att','XP%':'IXP%','FGM':'IFG_Made','FGA':'IFG_Att',\\\n",
    "                 'FG%':'IFG%','2PM':'I2pt_Made','Sfty':'ISfty','TD.3':'ITot_TD','Pts':'ITot_Pts','Rt':'IKR_Rt','Yds.4':'IKR_Yds',\\\n",
    "                 'Y/Rt':'IKR_Y/Rt','TD.4':'IKR_TD','Ret':'IPR_Rt','Yds.5':'IPR_Yds','Y/R.1':'IPR_Y/Rt','TD.5':'IPR_TD',\\\n",
    "                 'Sk.1':'ITack_Sk','Solo':'ITack_Solo','Ast':'ITack_Ast','Comb':'ITack_Tot','TFL':'ITack_TFL',\\\n",
    "                 'QBHits':'ITack_QBHits','Int.1':'IDef_Int','Yds.6':'IDef_IntYds','TD.6':'IDef_IntTD','PD':'IDef_PD',\\\n",
    "                 'Fmb':'IFmb_Fmb','FL':'IFmb_Lost','FF':'IFmb_Forced','FR':'IFmb_Recov','Yds.7':'IFmb_Yds','TD.7':'IFmb_TD'},\\\n",
    "                 inplace=True)\n",
    "\n",
    "    stats_cols = []\n",
    "    for col in stats.columns:\n",
    "        stats_cols.append(col)\n",
    "\n",
    "    stats.replace({'Away_Home':{'@':'Away',None:'Home'}},inplace=True)\n",
    "    stats[['IPass_Cmp','IPass_Att','IRec_Rec','IRec_Tgt','IXP_Made','IXP_Att','IFG_Made','IFG_Att']] = stats[['IPass_Cmp','IPass_Att','IRec_Rec','IRec_Tgt','IXP_Made','IXP_Att','IFG_Made','IFG_Att']].astype(float)\n",
    "    stats['IPass_Cmp%'] = stats['IPass_Cmp']/stats['IPass_Att']\n",
    "    stats['IRec_Ctch%'] = stats['IRec_Rec']/stats['IRec_Tgt']\n",
    "    stats['IXP%'] = stats['IXP_Made']/stats['IXP_Att']\n",
    "    stats['IFG%'] = stats['IFG_Made']/stats['IFG_Att']\n",
    "    stats[stats_cols[11:]] = stats[stats_cols[11:]].astype(float)\n",
    "    stats[stats_cols[11:]] = stats[stats_cols[11:]].fillna(value=0)\n",
    "    stats['Date'] = pd.to_datetime(stats['Date'],errors='coerce',format='%Y-%m-%d')\n",
    "    stats.insert(loc=8,column='Year',value=stats['Date'].dt.year)\n",
    "    stats['Player'] = stats['Player'].astype(str)\n",
    "    stats['Week'] = stats['Week'].astype(str)\n",
    "    stats['Year'] = stats['Year'].astype(str)\n",
    "    stats['Player'] = stats['Player']+' '\n",
    "    stats.replace({'Player':{' Jr. ':'',' Jr ':'',' Sr. ':'',' Sr ':'',' III ':'',' II ':'',' IV ':'',' V ':''}},regex=True,inplace=True)\n",
    "    stats['Player'] = stats['Player'].str.strip(' ')\n",
    "\n",
    "    print('Player stats data cleaned.')\n",
    "\n",
    "    injury = pd.read_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\nfl_injuryreport_{Start_Year}_{End_Year}.csv',low_memory=False)\n",
    "    nfl_weeks = pd.read_excel(r'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\NFL Week Dates.xlsx',sheet_name='NFL Week Dates')\n",
    "    injury.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "    injury = pd.melt(injury,id_vars=['Player','Team','Year'],var_name='Date', value_name='Status')\n",
    "    injury[['Date','Opp']] = injury.Date.str.split('vs. ',expand=True)\n",
    "    injury[['Month','Day']] = injury.Date.str.split('/',expand=True)\n",
    "    injury[['Status','Injury']] = injury.Status.str.split(\":\",expand=True)\n",
    "    injury.dropna(axis=0,subset=['Status','Injury'],how='all',inplace=True)\n",
    "    injury[['Year','Month','Day']] = injury[['Year','Month','Day']].astype(int)\n",
    "    injury['Date'] = injury['Date']+'/'+(np.where(injury['Month']<=2,injury['Year']+1,injury['Year'])).astype(str)\n",
    "    injury['Date'] = pd.to_datetime(injury['Date'])\n",
    "    nfl_weeks['Week'] = nfl_weeks['Week'].astype(str)\n",
    "    def pre_thu(d):\n",
    "        days_behind = 3 - d.weekday()\n",
    "        if days_behind > 0:\n",
    "            days_behind -= 7\n",
    "        return d + dt.timedelta(days_behind)\n",
    "    injury['week_start_nfl'] = injury['Date'].apply(pre_thu)\n",
    "    injury = pd.merge(left=injury,right=nfl_weeks,how='left',left_on='week_start_nfl',right_on='Start Date')\n",
    "    injury.replace({'Team':\\\n",
    "                       {'crd':'ARI', 'atl':'ATL', 'rav':'BAL', 'buf':'BUF', 'car':'CAR', 'chi':'CHI', 'cin':'CIN',\\\n",
    "                        'cle':'CLE', 'dal':'DAL', 'den':'DEN', 'det':'DET', 'gnb':'GNB','htx':'HOU','clt':'IND',\\\n",
    "                        'jax':'JAX','kan':'KAN','sdg':'LAC','ram':'LAR','mia':'MIA','min':'MIN','nor':'NOR','nwe':'NWE',\\\n",
    "                        'nyg':'NYG','nyj':'NYJ','rai':'OAK','phi':'PHI','pit':'PIT','sea':'SEA','sfo':'SFO','tam':'TAM',\\\n",
    "                        'oti':'TEN','was':'WAS'}},inplace=True)\n",
    "    injury['Injury'] = injury['Injury'].str.strip(' ')\n",
    "    injury.replace({'Injury':{'right':'','left':'','Right':'','Left':'','Biceps':'Bicep',\\\n",
    "                              'Triceps':'Tricep','Ankles':'Ankle','hip':'Hip','Hips':'Hip','Knees':'Knee',\\\n",
    "                              'Virus':'Illness','Triceps':'Tricep','Oblique':'Abdomen',\\\n",
    "                              'NotInjuryRelated':'Not Injury Related','MedicalIllness':'Illness',\\\n",
    "                              'LowerLeg':'Lower Leg','CoreMuscle':'Abdomen','Abdominal':'Abdomen'}},\\\n",
    "                               regex=True,inplace=True)\n",
    "    injury['Player'] = injury['Player']+' '\n",
    "    injury.replace({'Player':{' Jr. ':'',' Jr ':'',' Sr. ':'',' Sr ':'',' III ':'',' II ':'',' IV ':'',' V ':''}},regex=True,inplace=True)\n",
    "    injury['Player'] = injury['Player'].str.strip(' ')\n",
    "    injury.drop(['Month','Day','week_start_nfl','Start Date'],axis=1,inplace=True)\n",
    "    injury.dropna(subset=['Week'],inplace=True)\n",
    "    injury[['Player','Week','Year']] = injury[['Player','Week','Year']].astype(str)\n",
    "    \n",
    "    print('Injury data cleaned.')\n",
    "    \n",
    "    team1 = pd.read_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\nflteam_data_1_{Start_Year}_{End_Year}.csv')\n",
    "    team2 = pd.read_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\nflteam_data_2_{Start_Year}_{End_Year}.csv')\n",
    "    team1.dropna(thresh=10,inplace=True)\n",
    "    team2.dropna(thresh=10,inplace=True)\n",
    "    team1.drop('LTime',axis=1,inplace=True)\n",
    "    team2.drop(['LTime'],axis=1,inplace=True)\n",
    "    test1 = team1.columns\n",
    "    test2 = team2.columns\n",
    "    team1.rename(columns={'Tm':'Team','Unnamed: 5':'Away_Home','PF':'Points_For','PA':'Points_Against','PC':'Points_Comb',\\\n",
    "                         'vs. Line':'Vs_Line','Cmp':'TPass_Cmp','Att':'TPass_Att','Cmp%':'TPass_Cmp%','Yds':'TPass_Yds',\\\n",
    "                          'TD':'TPass_TD','Int':'TPass_Int','Sk':'TSack','Yds.1':'TSack_Yds','Rate':'TQB_Rate',\\\n",
    "                          'Att.1':'TRush_Att','Yds.2':'TRush_Yds','Y/A':'TRush_Y/A','TD.1':'TRush_TD','Tot':'TTot_Yds',\\\n",
    "                          'Ply':'TO_Play#','Y/P':'TO_Y/P','DPly':'TD_Play#','DY/P':'TD_Y/P','TO':'TTot_TO','ToP':'TO_ToP',\\\n",
    "                          'Time.1':'TGame_Dur','Yds.3':'TPen_Yds','OppPen':'TOpp_Pen','OppYds':'TOpp_Pen_Yds',\\\n",
    "                          'CombPen':'TComb_Pen','CombPenYds':'TComb_Pen_Yds','1stD':'T1st_Downs','Rsh':'T1st_by_Rsh',\\\n",
    "                          'Pass':'T1st_by_Pass','Pen.1':'T1st_by_Pen','3DAtt':'T3rd_Down_Att','3DConv':'T3rd_Down_Conv',\\\n",
    "                          '3D%':'T3rd_Down%','4DAtt':'T4th_Down_Att','4DConv':'T4th_Down_Conv','4D%':'T4th_Down%',\\\n",
    "                          'TD.2':'TTot_TD','XPA':'TXP_Att','XPM':'TXP_Made','FGA':'TFG_Att','FGM':'TFG_Made','2PA':'T2Pt_Att',\\\n",
    "                          '2PM':'T2Pt_Made','Sfty':'TSfty','Pnt':'TTimes_Punted','Yds.4':'TPunt_Yds','Y/P.1':'TPunt_Yds_Avg'},inplace=True)\n",
    "    team2.rename(columns={'Tm':'Team','Unnamed: 5':'Away_Home','TD':'TOpp_Tot_TD','XPA':'TOpp_XP_Att','XPM':'TOpp_XP_Made',\\\n",
    "                          'Att':'TOpp_FG_Att','Md':'TOpp_FG_Made','Sfty':'TOpp_Sfty','Cmp':'TOpp_Pass_Cmp','Att.1':'TOpp_Pass_Att',\\\n",
    "                          'Cmp%':'TOpp_Pass_Cmp%','Yds':'TOpp_Pass_Yds','TD.1':'TOpp_Pass_TD','Int':'TOpp_Pass_Int','Sk':'TOpp_Sk',\\\n",
    "                          'Yds.1':'TOpp_Sk_Yds','Rate':'TOpp_QB_Rate','Att.2':'TOpp_Rush_Att','Yds.2':'TOpp_Rush_Yds',\\\n",
    "                          'Y/A':'TOpp_Rush_Y/A','TD.2':'TOpp_Rush_TD','Tot':'TOpp_Tot_Yds','TO':'TOpp_Tot_TO',\\\n",
    "                          '1stDOpp':'TOpp_1st_Downs','Rush':'TOpp_1st_by_Rsh','Pass':'TOpp_1st_by_Pass','Pen':'TOpp_1st_by_Pen',\\\n",
    "                          'Opp3DAtt':'TOpp_3rd_Down_Att','Opp3DConv':'TOpp_3rd_Down_Conv','Opp3D%':'TOpp_3rd_Down%',\\\n",
    "                          'Opp4DAtt':'TOpp_4th_Down_Att','Opp4DConv':'TOpp_4th_Down_Conv','Opp4D%':'TOpp_4th_Down%',\\\n",
    "                          'Rush.1':'TMargin_Rush','Pass.1':'TMargin_Pass','Tot.1':'TMargin_TotYds','TO.1':'TTO_TD',\\\n",
    "                          'KR':'TKR_TD','PR':'TPR_TD','IR':'TInt_TD','FR':'TFmb_TD','OR':'TOtherRet_TD',\\\n",
    "                          'RetTD':'TAll_Ret_TD','Q1':'TMar_Thru_Q1','Q2':'TMar_Thru_Q2','Q3':'TMar_Thru_Q3',\\\n",
    "                          'Q1.1':'TScore_Diff_Q1','Q2.1':'TScore_Diff_Q2','Q3.1':'TScore_Diff_Q3',\\\n",
    "                          'Q4':'TScore_Diff_Q4','1stHalf':'TScore_Diff_1stHalf','2ndHalf':'TScore_Diff_2ndHalf'},inplace=True)\n",
    "    \n",
    "    team = pd.merge(left=team1,right=team2,\\\n",
    "                     how='outer',\\\n",
    "                     on=['Team','Year','Date','Time','Away_Home','Opp','Week','G#','Day','Result','OT'])\n",
    "    team.set_index('Team',inplace=True)\n",
    "    team.drop('Tm',inplace=True)\n",
    "    team.reset_index(inplace=True)\n",
    "\n",
    "    team_cols = []\n",
    "\n",
    "    for col in team.columns:\n",
    "        team_cols.append(col)\n",
    "\n",
    "    team.replace({'Away_Home':{'@':'Away',None:'Home'}},inplace=True)\n",
    "    team[team_cols[11:]] = team[team_cols[11:]].fillna(value=0)\n",
    "    team[['TPass_Cmp','TPass_Att','T3rd_Down_Att','T3rd_Down_Conv','T4th_Down_Att',\\\n",
    "          'T4th_Down_Conv','TOpp_Pass_Cmp','TOpp_Pass_Att','TOpp_3rd_Down_Att',\\\n",
    "          'TOpp_3rd_Down_Conv','TOpp_4th_Down_Att','TOpp_4th_Down_Conv']] = team[['TPass_Cmp','TPass_Att','T3rd_Down_Att',\\\n",
    "                                                                                  'T3rd_Down_Conv','T4th_Down_Att',\\\n",
    "                                                                                  'T4th_Down_Conv','TOpp_Pass_Cmp',\\\n",
    "                                                                                  'TOpp_Pass_Att','TOpp_3rd_Down_Att',\\\n",
    "                                                                                  'TOpp_3rd_Down_Conv','TOpp_4th_Down_Att',\\\n",
    "                                                                                  'TOpp_4th_Down_Conv']].astype(float)\n",
    "    team['TPass_Cmp%'] = team['TPass_Cmp']/team['TPass_Att']\n",
    "    team['T3rd_Down%'] = team['T3rd_Down_Conv']/team['T3rd_Down_Att']\n",
    "    team['T4th_Down%'] = team['T4th_Down_Conv']/team['T4th_Down_Att']\n",
    "    team['TOpp_Pass_Cmp%'] = team['TOpp_Pass_Cmp']/team['TOpp_Pass_Att']\n",
    "    team['TOpp_3rd_Down%'] = team['TOpp_3rd_Down_Conv']/team['TOpp_3rd_Down_Att']\n",
    "    team['TOpp_4th_Down%'] = team['TOpp_4th_Down_Conv']/team['TOpp_4th_Down_Att']\n",
    "    team['Date'] = pd.to_datetime(team['Date'],errors='coerce',format='%Y-%m-%d')\n",
    "    team['TGame_Dur'] = team['TGame_Dur']+':00'\n",
    "    team['TO_ToP'] = '00:'+team['TO_ToP']\n",
    "    team['TGame_Dur'] = pd.to_timedelta(team['TGame_Dur'],errors='coerce')\n",
    "    team['TGame_Dur'] = team['TGame_Dur'].dt.total_seconds()\n",
    "    team['TO_ToP'] = pd.to_timedelta(team['TO_ToP'],errors='coerce')\n",
    "    team['TO_ToP'] = team['TO_ToP'].dt.total_seconds()\n",
    "    team[team_cols[11:16]] = team[team_cols[11:16]].astype(float)\n",
    "    team[team_cols[17]] = team[team_cols[17]].astype(float)\n",
    "    team[team_cols[19:]] = team[team_cols[19:]].astype(float)\n",
    "    team.insert(loc=9,column='Month',value=team['Date'].dt.month)\n",
    "    team = team[team['Week']<=17]\n",
    "\n",
    "    print('Team data cleaned.')\n",
    "\n",
    "    stats_snaps = pd.merge(left=stats,right=snaps,how='outer',on=['Player','Year','Week'])\n",
    "    stats_snaps['Team_x'] = stats_snaps['Team_x'].fillna(stats_snaps['Team_y'])\n",
    "    stats_snaps['Pos_x'] = stats_snaps['Pos_y'].fillna(stats_snaps['Pos_x'])\n",
    "    stats_snaps.drop(['Team_y','Pos_y'],axis=1,inplace=True)\n",
    "    stats_snaps.rename(columns={'Team_x':'Team','Pos_x':'Pos'},inplace=True)\n",
    "\n",
    "    print('Stats and snaps data merged.')\n",
    "\n",
    "    stats_snaps_injury = pd.merge(left=stats_snaps,right=injury,how='outer',on=['Player','Year','Week'])\n",
    "    stats_snaps_injury['Date_x'] = stats_snaps_injury['Date_x'].fillna(stats_snaps_injury['Date_y'])\n",
    "    stats_snaps_injury['Team_x'] = stats_snaps_injury['Team_x'].fillna(stats_snaps_injury['Team_y'])\n",
    "    stats_snaps_injury['Opp_x'] = stats_snaps_injury['Opp_x'].fillna(stats_snaps_injury['Opp_y'])\n",
    "    stats_snaps_injury.drop(['Date_y','Team_y','Opp_y'],axis=1,inplace=True)\n",
    "    stats_snaps_injury.rename(columns={'Date_x':'Date','Team_x':'Team','Opp_x':'Opp'},inplace=True)\n",
    "\n",
    "    print('Stats, snaps, and injuries merged.')\n",
    "    \n",
    "    combined = pd.merge(left=stats_snaps_injury,right=team,how='outer',on=['Team','Year','Week'])\n",
    "    combined['Date_x'] = combined['Date_x'].fillna(combined['Date_y'])\n",
    "    combined['Away_Home_x'] = combined['Away_Home_x'].fillna(combined['Away_Home_y'])\n",
    "    combined['Opp_x'] = combined['Opp_x'].fillna(combined['Opp_y'])\n",
    "    combined['G#_x'] = combined['G#_x'].fillna(combined['G#_y'])\n",
    "    combined['Day_x'] = combined['Day_x'].fillna(combined['Day_y'])\n",
    "    combined['Result_x'] = combined['Result_x'].fillna(combined['Result_y'])\n",
    "    combined.drop(['Date_y','Away_Home_y','Opp_y','G#_y','Day_y','Result_y'],axis=1,inplace=True)\n",
    "    combined.rename(columns={'Date_x':'Date','Away_Home_x':'Away_Home','Opp_x':'Opp','G#_x':'G#','Day_x':'Day','Result_x':'Result'},inplace=True)\n",
    "    \n",
    "    combined.to_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\nfl_total_{Start_Year}_{End_Year}.csv',index=False)\n",
    "    \n",
    "    print(\"Done\")\n",
    "    \n",
    "def injury_report_inital(Start_Year,End_Year):\n",
    "    injury_df = pd.read_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\nfl_total_{Start_Year}_{End_Year}.csv')\n",
    "    injury_df.drop_duplicates(['Player','Year','Injury'],inplace=True)\n",
    "    injury_df.to_csv(rf'C:\\Users\\cudde\\OneDrive\\Podcasting\\Fantasy Sidelines\\Injury Data Python\\Data_Collect_Clean\\nfl_data\\nfl_total_injury_initial_{Start_Year}_{End_Year}.csv',index=False)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Start_Year = 2016\n",
    "End_Year = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data_scrape(Start_Year,End_Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "player_snap_scrape(Start_Year,End_Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_reports_scrape(Start_Year,End_Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats_scape(Start_Year,End_Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean(Start_Year,End_Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injury_report_inital(Start_Year,End_Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
