{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc1845-7b79-4e42-9a0c-b1c7cff1bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import date, timedelta\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193ad5a-fe8f-4f17-b16c-c241f332b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 2015\n",
    "players = pd.read_csv('../data/database-players.csv')\n",
    "players = players[players['Last_Year'] >= s]\n",
    "nfl_weeks = pd.read_csv('../data/NFL-Week-Dates.csv')\n",
    "nfl_weeks['Week'] = nfl_weeks['Week'].astype(str)\n",
    "def pre_thu(d):\n",
    "    days_behind = 3 - d.weekday()\n",
    "    if days_behind > 0:\n",
    "        days_behind -= 7\n",
    "    return d + dt.timedelta(days_behind)\n",
    "def findnth(haystack, needle, n):\n",
    "    parts= haystack.split(needle, n+1)\n",
    "    if len(parts)<=n+1:\n",
    "        return -1\n",
    "    return len(haystack)-len(parts[-1])-len(needle)\n",
    "def renaming_cols(col):\n",
    "    if \"Unnamed:\" in col:\n",
    "        new = col[findnth(col, \"'\", 2)+1:-2]\n",
    "    elif \"Passing\" in col or \"Rushing\" in col or \"Receiving\" in col or \"Fumbles\" in col or \"Scoring\" in col or \"Tackles\" in col or \"Punting\" in col:\n",
    "        new = col[findnth(col, \"'\", 0)+1:findnth(col, \"'\", 1)] + \"_\" + col[findnth(col, \"'\", 2)+1:findnth(col, \"'\", 3)]\n",
    "    elif \"Punt Returns\" in col or \"ST Snaps\" in col or \"Kick Returns\" in col:\n",
    "        new = col[findnth(col, \"'\", 0)+1:findnth(col, \" \", 0)] + \"_\" + col[findnth(col, \" \", 0)+1:findnth(col, \"'\", 1)] + \"_\" + col[findnth(col, \"'\", 2)+1:findnth(col, \"'\", 3)]\n",
    "    elif \"Def. Snaps\" in col or \"Off. Snaps\" in col:\n",
    "        new = col[findnth(col, \"'\", 0)+1:findnth(col, \" \", 0)-1] + \"_\" + col[findnth(col, \" \", 0)+1:findnth(col, \"'\", 1)] + \"_\" + col[findnth(col, \"'\", 2)+1:findnth(col, \"'\", 3)]\n",
    "    elif \"Def Interceptions\" in col:\n",
    "        new = col[findnth(col, \"'\", 0)+1:findnth(col, \" \", 0)] + \"_\" + col[findnth(col, \" \", 0)+1:findnth(col, \" \", 0)+4] + \"_\" + col[findnth(col, \"'\", 2)+1:findnth(col, \"'\", 3)]\n",
    "    else:\n",
    "        new = col\n",
    "    return new\n",
    "def player_address_rename(col):\n",
    "    if \"Player_Address\" in col:\n",
    "        new = col[:len(\"Player_Address\")]\n",
    "    else:\n",
    "        new = col\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c29ec65-2bfc-42e3-9a95-aea0e1209f65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# player stats clean\n",
    "start = time.time()\n",
    "stats = pd.read_csv(f'../data/raw-data/player-weekly-stats-{s}-raw.csv', low_memory=False)\n",
    "stats = stats.rename(columns=renaming_cols)\n",
    "stats = stats.rename(columns = {\"Unnamed: 6_level_1\": \"Home_Away\", \"Tm\": \"Team\", \"Passing_Yds.1\": \"Passing_Sk_Yds\", \"GS\": \"Gm_Start\", \"G#\": \"Gm_Num\"})\n",
    "stats = pd.merge(left=stats, \n",
    "                 right=players, \n",
    "                 how='outer', \n",
    "                 left_on='Player_Address', \n",
    "                 right_on='Address')\n",
    "stats = stats.groupby(stats.columns, axis=1).sum()\n",
    "stats.drop(['First_Year', 'Last_Year', 'Rk', 'Address'], axis=1, inplace=True)\n",
    "stats.replace({'Home_Away': {'@': 'Away', 0: 'Home'}, \n",
    "               'Gm_Start': {'*': True, 0: False}}, inplace=True)\n",
    "stats.dropna(subset=['Player_Address'], inplace=True)\n",
    "stats[['Off_Snaps_Pct', \n",
    "       'Def_Snaps_Pct', \n",
    "       'ST_Snaps_Pct',\n",
    "       'Player_Address', \n",
    "       'Week']] = stats[['Off_Snaps_Pct', \n",
    "                         'Def_Snaps_Pct', \n",
    "                         'ST_Snaps_Pct', \n",
    "                         'Player_Address', \n",
    "                         'Week']].astype(str)\n",
    "stats['Off_Snaps_Pct'] = list(map(lambda x: x[:-1], stats['Off_Snaps_Pct'].values))\n",
    "stats['Def_Snaps_Pct'] = list(map(lambda x: x[:-1], stats['Def_Snaps_Pct'].values))\n",
    "stats['ST_Snaps_Pct'] = list(map(lambda x: x[:-1], stats['ST_Snaps_Pct'].values))\n",
    "stats['Player_Address'] = list(map(lambda x: x[11:], stats['Player_Address'].values))\n",
    "stats['Date'] = pd.to_datetime(stats['Date'], errors='coerce', format='%Y-%m-%d')\n",
    "stats = stats[['Player_Address', 'Player', 'Position', 'Age', \n",
    "               'Team', 'Home_Away', 'Opp', 'Result', 'Week', \n",
    "               'Gm_Num', 'Season', 'Gm_Start', 'Date', 'Off_Snaps_Num',\n",
    "               'Off_Snaps_Pct', 'Def_Snaps_Num', 'Def_Snaps_Pct',\n",
    "               'ST_Snaps_Num', 'ST_Snaps_Pct', 'Passing_Att',  'Passing_Cmp',\n",
    "               'Passing_Cmp%', 'Passing_Yds', 'Passing_TD', 'Passing_Int',\n",
    "               'Passing_Rate', 'Passing_Sk', 'Passing_Sk_Yds', 'Passing_Y/A',\n",
    "               'Passing_AY/A', 'Rushing_Att', 'Rushing_Yds', 'Rushing_Y/A',\n",
    "               'Rushing_TD', 'Receiving_Tgt', 'Receiving_Rec', 'Receiving_Yds', 'Receiving_TD',\n",
    "               'Receiving_Y/R', 'Receiving_Ctch%', 'Receiving_Y/Tgt', 'Kick_Returns_Rt',\n",
    "               'Kick_Returns_Yds', 'Kick_Returns_Y/Rt', 'Kick_Returns_TD', 'Punt_Returns_Ret', 'Punt_Returns_Yds',\n",
    "               'Punt_Returns_TD', 'Punt_Returns_Y/R', 'Punting_Pnt', 'Punting_Yds', 'Punting_Y/P',\n",
    "               'Punting_Blck', 'Scoring_TD', 'Scoring_Pts', 'Scoring_XPM',\n",
    "               'Scoring_XPA', 'Scoring_XP%', 'Scoring_FGM', 'Scoring_FGA',\n",
    "               'Scoring_FG%', 'Scoring_2PM', 'Scoring_Sfty', 'Sk',\n",
    "               'Tackles_Solo', 'Tackles_Ast', 'Tackles_Comb', 'Tackles_TFL',\n",
    "               'Tackles_QBHits', 'Def_Int_Int', 'Def_Int_Yds', 'Def_Int_TD',\n",
    "               'Def_Int_PD', 'Fumbles_Fmb', 'Fumbles_FL', 'Fumbles_FF',\n",
    "               'Fumbles_FR', 'Fumbles_Yds', 'Fumbles_TD']]\n",
    "for c in stats.columns[13:]:\n",
    "    stats[c] = pd.to_numeric(stats[c], errors='coerce')\n",
    "stats.to_csv(f'../data/clean-data/stats-{s}.csv', index=False)\n",
    "\n",
    "# player injurys clean\n",
    "injury = pd.read_csv(f'../data/raw-data/nfl-injury-report-{s}-raw.csv', low_memory=False)\n",
    "cols = [col for col in injury.columns if \"Player_Address\" in col]\n",
    "injury[\"Player_Address\"] = injury[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "injury = injury.drop(cols[1:], axis=1)\n",
    "injury = pd.melt(injury,\n",
    "                 id_vars=['Player', 'Team', 'Season', 'Player_Address'], \n",
    "                 var_name='Date', \n",
    "                 value_name='Status')\n",
    "injury[['Date','Opp']] = injury.Date.str.split('vs. ', expand=True)\n",
    "injury[['Month','Day']] = injury.Date.str.split('/', expand=True)\n",
    "injury[['Status','Injury']] = injury.Status.str.split(\":\", expand=True)\n",
    "injury.dropna(axis=0, subset=['Status','Injury'], how='all', inplace=True)\n",
    "injury[['Season', 'Month', 'Day']] = injury[['Season', 'Month', 'Day']].astype(int)\n",
    "injury['Date'] = injury['Date'] + '/' + (np.where(injury['Month'] <= 2, injury['Season'] + 1, injury['Season'])).astype(str)\n",
    "injury['Date'] = pd.to_datetime(injury['Date'])\n",
    "injury['week_start_nfl'] = injury['Date'].apply(pre_thu)\n",
    "nfl_weeks['Start Date'] = pd.to_datetime(nfl_weeks['Start Date'])\n",
    "injury = pd.merge(left=injury, \n",
    "                  right=nfl_weeks, \n",
    "                  how='left', \n",
    "                  left_on='week_start_nfl', \n",
    "                  right_on='Start Date')\n",
    "injury.replace({'Team':\n",
    "                   {'crd': 'ARI', 'atl': 'ATL', 'rav': 'BAL', 'buf': 'BUF', \n",
    "                    'car': 'CAR', 'chi': 'CHI', 'cin': 'CIN', 'cle': 'CLE', \n",
    "                    'dal': 'DAL', 'den': 'DEN', 'det': 'DET', 'gnb': 'GNB',\n",
    "                    'htx': 'HOU', 'clt': 'IND', 'jax': 'JAX', 'kan': 'KAN', \n",
    "                    'sdg': 'LAC', 'ram': 'LAR', 'mia': 'MIA', 'min': 'MIN', \n",
    "                    'nor': 'NOR', 'nwe': 'NWE', 'nyg': 'NYG', 'nyj': 'NYJ', \n",
    "                    'rai': 'OAK', 'phi': 'PHI', 'pit': 'PIT', 'sea': 'SEA',\n",
    "                    'sfo': 'SFO', 'tam': 'TAM', 'oti': 'TEN', 'was': 'WAS'}},\n",
    "               inplace=True)\n",
    "injury['Injury'] = injury['Injury'].str.strip(' ')\n",
    "injury.replace({\"Player_Address\": {\"_\": \"\", \"nan\": \"\"}}, regex=True, inplace=True)\n",
    "injury = pd.merge(left=injury,  \n",
    "                  right=players, \n",
    "                  how='outer', \n",
    "                  left_on='Player_Address',\n",
    "                  right_on='Address')\n",
    "injury.rename(columns={\"Player_x\": \"Player\"}, inplace=True)\n",
    "injury.drop(['Month', 'Day', 'week_start_nfl', 'Start Date', 'First_Year', 'Last_Year', 'Player_y'], axis=1, inplace=True)\n",
    "injury['Date'] = pd.to_datetime(injury['Date'], errors='coerce', format='%Y-%m-%d')\n",
    "injury.dropna(subset=['Player_Address'], inplace=True)\n",
    "injury['Player_Address'] = list(map(lambda x: x[11:], injury['Player_Address'].values))\n",
    "injury = injury[[\"Player\", \"Team\", \"Season\", \"Player_Address\", \"Date\", \"Status\", \"Opp\", \"Injury\", \"Week\", \"Position\"]]\n",
    "injury.to_csv(f'../data/clean-data/injury-{s}.csv', index=False)\n",
    "\n",
    "# combine stats and injuries\n",
    "stats = pd.read_csv(f'../data/clean-data/stats-{s}.csv')\n",
    "injury = pd.read_csv(f'../data/clean-data/injury-{s}.csv')\n",
    "nfl_data = stats.merge(injury, \n",
    "                       how=\"outer\",\n",
    "                       left_on=[\"Player_Address\", \"Week\"],\n",
    "                       right_on=[\"Player_Address\", \"Week\"])\n",
    "nfl_data[\"Player_x\"] = nfl_data[\"Player_x\"].fillna(nfl_data[\"Player_y\"])\n",
    "nfl_data[\"Position_x\"] = nfl_data[\"Position_x\"].fillna(nfl_data[\"Position_y\"])\n",
    "nfl_data[\"Team_x\"] = nfl_data[\"Team_x\"].fillna(nfl_data[\"Team_y\"])\n",
    "nfl_data[\"Opp_x\"] = nfl_data[\"Opp_x\"].fillna(nfl_data[\"Opp_y\"])\n",
    "nfl_data[\"Date_x\"] = nfl_data[\"Date_x\"].fillna(nfl_data[\"Date_y\"])\n",
    "nfl_data[\"Season_x\"] = nfl_data[\"Season_x\"].fillna(nfl_data[\"Season_y\"])\n",
    "nfl_data = nfl_data.rename(columns={\"Player_x\": \"Player\", \n",
    "                                    \"Position_x\": \"Position\", \n",
    "                                    \"Team_x\": \"Team\", \n",
    "                                    \"Opp_x\": \"Opp\", \n",
    "                                    \"Date_x\": \"Date\", \n",
    "                                    \"Season_x\": \"Season\", \n",
    "                                    \"Week_x\": \"Week\"})\n",
    "nfl_data = nfl_data[['Player_Address', 'Player', 'Position', 'Age', \n",
    "                     'Team', 'Home_Away', 'Opp', 'Result', 'Date', 'Week', \n",
    "                     'Gm_Num', 'Season', 'Status', 'Injury', 'Gm_Start', 'Off_Snaps_Num',\n",
    "                     'Off_Snaps_Pct', 'Def_Snaps_Num', 'Def_Snaps_Pct',\n",
    "                     'ST_Snaps_Num', 'ST_Snaps_Pct', 'Passing_Att',  'Passing_Cmp',\n",
    "                     'Passing_Cmp%', 'Passing_Yds', 'Passing_TD', 'Passing_Int',\n",
    "                     'Passing_Rate', 'Passing_Sk', 'Passing_Sk_Yds', 'Passing_Y/A',\n",
    "                     'Passing_AY/A', 'Rushing_Att', 'Rushing_Yds', 'Rushing_Y/A',\n",
    "                     'Rushing_TD', 'Receiving_Tgt', 'Receiving_Rec', 'Receiving_Yds', 'Receiving_TD',\n",
    "                     'Receiving_Y/R', 'Receiving_Ctch%', 'Receiving_Y/Tgt', 'Kick_Returns_Rt',\n",
    "                     'Kick_Returns_Yds', 'Kick_Returns_Y/Rt', 'Kick_Returns_TD', 'Punt_Returns_Ret', 'Punt_Returns_Yds',\n",
    "                     'Punt_Returns_TD', 'Punt_Returns_Y/R', 'Punting_Pnt', 'Punting_Yds', 'Punting_Y/P',\n",
    "                     'Punting_Blck', 'Scoring_TD', 'Scoring_Pts', 'Scoring_XPM',\n",
    "                     'Scoring_XPA', 'Scoring_XP%', 'Scoring_FGM', 'Scoring_FGA',\n",
    "                     'Scoring_FG%', 'Scoring_2PM', 'Scoring_Sfty', 'Sk',\n",
    "                     'Tackles_Solo', 'Tackles_Ast', 'Tackles_Comb', 'Tackles_TFL',\n",
    "                     'Tackles_QBHits', 'Def_Int_Int', 'Def_Int_Yds', 'Def_Int_TD',\n",
    "                     'Def_Int_PD', 'Fumbles_Fmb', 'Fumbles_FL', 'Fumbles_FF',\n",
    "                     'Fumbles_FR', 'Fumbles_Yds', 'Fumbles_TD']]\n",
    "nfl_data.to_csv(f'../data/clean-data/nfl-{s}.csv', index=False)\n",
    "end = time.time()\n",
    "print(f'Done with season {s}.', f'Time to compelte: {end-start}.', sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a77c17-e7b3-4b8b-a65b-98f3721c7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database of all athletes that sustained an injury and what their production was post injury for the remainder of the season\n",
    "start = time.time()\n",
    "df = pd.read_csv(f'../data/clean-data/nfl-{s}.csv',low_memory=False)\n",
    "df.sort_values(['Player','Week'],inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(['index'],axis=1,inplace=True)\n",
    "# create list of status's to be able to identify were to split the rows\n",
    "status = df['Status'].dropna().unique().tolist()\n",
    "# create a database to located the index of the first instance of an injury\n",
    "Player = df.loc[df['Status'].isin(status)].drop_duplicates(subset=['Player']).index.unique().tolist()\n",
    "# split out the rows then save them to a separate dataframe and export to csv\n",
    "inj_df = pd.DataFrame()\n",
    "for i in range(0,len(Player)):\n",
    "    idx = df[df['Player']==df['Player'][Player[i]]].tail(1)\n",
    "    inj = df.loc[Player[i]-1:idx.index.values.astype(int)[0]]\n",
    "    inj_df = pd.concat([inj_df,inj])\n",
    "inj_df['Inj_Week'] = 0\n",
    "inj_df['Inj_Week'] = inj_df.groupby('Player').cumcount()\n",
    "\n",
    "# create a database of all athletes that were healthy or healthy until sustaining an injury\n",
    "df.sort_values(['Player','Week'],inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(['index'],axis=1,inplace=True)\n",
    "# create list of status's to be able to identify were to split the rows\n",
    "status = df['Status'].dropna().unique().tolist()\n",
    "# create a database to locate the index of the first instance of an injury\n",
    "Player = df.loc[df['Status'].isin(status)].drop_duplicates(subset=['Player']).index.unique().tolist()\n",
    "# split out the rows then save them to a separate dataframe and export to csv\n",
    "healthy_df = pd.DataFrame()\n",
    "for i in range(0,len(Player)):\n",
    "    idx = df[df['Player']==df['Player'][Player[i]]].head(1)\n",
    "    healthy = df.loc[idx.index.values.astype(int)[0]:Player[i]-1]\n",
    "    healthy_df = pd.concat([healthy_df,healthy])\n",
    "healthy_df['Healthy_Week'] = 0\n",
    "healthy_df['Healthy_Week'] = healthy_df.groupby('Player').cumcount()+1\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2903961-386e-431c-983d-420d886e278d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1677ffc-cc06-4034-b149-8a3b3c0f3210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6efad2-767f-4c33-998b-ee53a55d09bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f60dc-7ed1-4c41-8ba9-7370f236e320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22db9c-0697-4173-b34a-c3b690b11f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d2268-9a43-4941-a546-15c2651f0d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b55b0-9c6c-4be9-86c8-5863ddff65d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d3558-5fed-4a7d-b063-efcbd8492fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2145e5a-ec74-4315-9de8-f38becd50de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
