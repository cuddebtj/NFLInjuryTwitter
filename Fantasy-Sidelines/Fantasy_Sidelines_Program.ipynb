{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dash, requests, os, time, dash_table\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from dash.dependencies import Input, Output\n",
    "from dotenv import load_dotenv\n",
    "from dash_table.Format import Format, Scheme, Trim\n",
    "from jupyter_dash import JupyterDash\n",
    "load_dotenv()\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def team_data_clean(Season):\n",
    "    # begin cleaning team data\n",
    "    start = time.time()\n",
    "    # opening both csv files into dataframes for cleaning and combining\n",
    "    team1 = pd.read_csv(f'../data/raw-data/nfl-team-data-{Season}-1-raw.csv')\n",
    "    team2 = pd.read_csv(f'../data/raw-data/nfl-team-data-{Season}-2-raw.csv')\n",
    "    # drop all blank rows\n",
    "    team1.dropna(thresh=10,inplace=True)\n",
    "    team2.dropna(thresh=10,inplace=True)\n",
    "    # drop useless columns\n",
    "    team1.drop('LTime',axis=1,inplace=True)\n",
    "    team2.drop(['LTime'],axis=1,inplace=True)\n",
    "    # rename columns\n",
    "    team1.rename(columns={'Tm':'Team','Unnamed: 5':'Away_Home','PF':'Points_For','PA':'Points_Against','PC':'Points_Comb',\\\n",
    "                         'vs. Line':'Vs_Line','Cmp':'TPass_Cmp','Att':'TPass_Att','Cmp%':'TPass_Cmp%','Yds':'TPass_Yds',\\\n",
    "                          'TD':'TPass_TD','Int':'TPass_Int','Sk':'TSack','Yds.1':'TSack_Yds','Rate':'TQB_Rate',\\\n",
    "                          'Att.1':'TRush_Att','Yds.2':'TRush_Yds','Y/A':'TRush_Y/A','TD.1':'TRush_TD','Tot':'TTot_Yds',\\\n",
    "                          'Ply':'TO_Play#','Y/P':'TO_Y/P','DPly':'TD_Play#','DY/P':'TD_Y/P','TO':'TTot_TO','ToP':'TO_ToP',\\\n",
    "                          'Time.1':'TGame_Dur','Yds.3':'TPen_Yds','OppPen':'TOpp_Pen','OppYds':'TOpp_Pen_Yds',\\\n",
    "                          'CombPen':'TComb_Pen','CombPenYds':'TComb_Pen_Yds','1stD':'T1st_Downs','Rsh':'T1st_by_Rsh',\\\n",
    "                          'Pass':'T1st_by_Pass','Pen.1':'T1st_by_Pen','3DAtt':'T3rd_Down_Att','3DConv':'T3rd_Down_Conv',\\\n",
    "                          '3D%':'T3rd_Down%','4DAtt':'T4th_Down_Att','4DConv':'T4th_Down_Conv','4D%':'T4th_Down%',\\\n",
    "                          'TD.2':'TTot_TD','XPA':'TXP_Att','XPM':'TXP_Made','FGA':'TFG_Att','FGM':'TFG_Made','2PA':'T2Pt_Att',\\\n",
    "                          '2PM':'T2Pt_Made','Sfty':'TSfty','Pnt':'TTimes_Punted','Yds.4':'TPunt_Yds','Y/P.1':'TPunt_Yds_Avg','Year':'Season'},inplace=True)\n",
    "    team2.rename(columns={'Tm':'Team','Unnamed: 5':'Away_Home','TD':'TOpp_Tot_TD','XPA':'TOpp_XP_Att','XPM':'TOpp_XP_Made',\\\n",
    "                          'Att':'TOpp_FG_Att','Md':'TOpp_FG_Made','Sfty':'TOpp_Sfty','Cmp':'TOpp_Pass_Cmp','Att.1':'TOpp_Pass_Att',\\\n",
    "                          'Cmp%':'TOpp_Pass_Cmp%','Yds':'TOpp_Pass_Yds','TD.1':'TOpp_Pass_TD','Int':'TOpp_Pass_Int','Sk':'TOpp_Sk',\\\n",
    "                          'Yds.1':'TOpp_Sk_Yds','Rate':'TOpp_QB_Rate','Att.2':'TOpp_Rush_Att','Yds.2':'TOpp_Rush_Yds',\\\n",
    "                          'Y/A':'TOpp_Rush_Y/A','TD.2':'TOpp_Rush_TD','Tot':'TOpp_Tot_Yds','TO':'TOpp_Tot_TO',\\\n",
    "                          '1stDOpp':'TOpp_1st_Downs','Rush':'TOpp_1st_by_Rsh','Pass':'TOpp_1st_by_Pass','Pen':'TOpp_1st_by_Pen',\\\n",
    "                          'Opp3DAtt':'TOpp_3rd_Down_Att','Opp3DConv':'TOpp_3rd_Down_Conv','Opp3D%':'TOpp_3rd_Down%',\\\n",
    "                          'Opp4DAtt':'TOpp_4th_Down_Att','Opp4DConv':'TOpp_4th_Down_Conv','Opp4D%':'TOpp_4th_Down%',\\\n",
    "                          'Rush.1':'TMargin_Rush','Pass.1':'TMargin_Pass','Tot.1':'TMargin_TotYds','TO.1':'TTO_TD',\\\n",
    "                          'KR':'TKR_TD','PR':'TPR_TD','IR':'TInt_TD','FR':'TFmb_TD','OR':'TOtherRet_TD',\\\n",
    "                          'RetTD':'TAll_Ret_TD','Q1':'TMar_Thru_Q1','Q2':'TMar_Thru_Q2','Q3':'TMar_Thru_Q3',\\\n",
    "                          'Q1.1':'TScore_Diff_Q1','Q2.1':'TScore_Diff_Q2','Q3.1':'TScore_Diff_Q3',\\\n",
    "                          'Q4':'TScore_Diff_Q4','1stHalf':'TScore_Diff_1stHalf','2ndHalf':'TScore_Diff_2ndHalf','Year':'Season'},inplace=True)\n",
    "    \n",
    "    # merge the two dataframes based on team, season, date, time, away/home, opp, week, g#, dat, result, and ot\n",
    "    team = pd.merge(left=team1,right=team2,\\\n",
    "                     how='outer',\\\n",
    "                     on=['Team','Season','Date','Time','Away_Home','Opp','Week','G#','Day','Result','OT'])\n",
    "    team.set_index('Team',inplace=True)\n",
    "    # drop all rows that have headers in them\n",
    "    team.drop('Tm',inplace=True)\n",
    "    team.reset_index(inplace=True)\n",
    "\n",
    "    # create a list of all the column names in the team dataframe\n",
    "    team_cols = []\n",
    "    \n",
    "    for col in team.columns:\n",
    "        team_cols.append(col)\n",
    "\n",
    "    # cleaning the away/home column to show away or home instead of @\n",
    "    team.replace({'Away_Home':{'@':'Away',None:'Home'}},inplace=True)\n",
    "    team[team_cols[11:]] = team[team_cols[11:]].fillna(value=0)\n",
    "    # change datatype of the columns\n",
    "    team[['TPass_Cmp','TPass_Att','T3rd_Down_Att','T3rd_Down_Conv','T4th_Down_Att',\\\n",
    "          'T4th_Down_Conv','TOpp_Pass_Cmp','TOpp_Pass_Att','TOpp_3rd_Down_Att',\\\n",
    "          'TOpp_3rd_Down_Conv','TOpp_4th_Down_Att','TOpp_4th_Down_Conv']] = team[['TPass_Cmp','TPass_Att','T3rd_Down_Att',\\\n",
    "                                                                                  'T3rd_Down_Conv','T4th_Down_Att',\\\n",
    "                                                                                  'T4th_Down_Conv','TOpp_Pass_Cmp',\\\n",
    "                                                                                  'TOpp_Pass_Att','TOpp_3rd_Down_Att',\\\n",
    "                                                                                  'TOpp_3rd_Down_Conv','TOpp_4th_Down_Att',\\\n",
    "                                                                                  'TOpp_4th_Down_Conv']].astype(float)\n",
    "    # calculating the columns to show apporpriate values\n",
    "    team['TPass_Cmp%'] = team['TPass_Cmp']/team['TPass_Att']\n",
    "    team['T3rd_Down%'] = team['T3rd_Down_Conv']/team['T3rd_Down_Att']\n",
    "    team['T4th_Down%'] = team['T4th_Down_Conv']/team['T4th_Down_Att']\n",
    "    team['TOpp_Pass_Cmp%'] = team['TOpp_Pass_Cmp']/team['TOpp_Pass_Att']\n",
    "    team['TOpp_3rd_Down%'] = team['TOpp_3rd_Down_Conv']/team['TOpp_3rd_Down_Att']\n",
    "    team['TOpp_4th_Down%'] = team['TOpp_4th_Down_Conv']/team['TOpp_4th_Down_Att']\n",
    "    # changing dates/time to datetime values\n",
    "    team['Date'] = pd.to_datetime(team['Date'],errors='coerce',format='%Y-%m-%d')\n",
    "    team['TGame_Dur'] = team['TGame_Dur']+':00'\n",
    "    team['TO_ToP'] = '00:'+team['TO_ToP']\n",
    "    team['TGame_Dur'] = pd.to_timedelta(team['TGame_Dur'],errors='coerce')\n",
    "    team['TGame_Dur'] = team['TGame_Dur'].dt.total_seconds()\n",
    "    team['TO_ToP'] = pd.to_timedelta(team['TO_ToP'],errors='coerce')\n",
    "    team['TO_ToP'] = team['TO_ToP'].dt.total_seconds()\n",
    "    #changing datatypes of columns\n",
    "    team[team_cols[11:16]] = team[team_cols[11:16]].astype(float)\n",
    "    team[team_cols[17]] = team[team_cols[17]].astype(float)\n",
    "    team[team_cols[19:]] = team[team_cols[19:]].astype(float)\n",
    "    # adding month column\n",
    "    team.insert(loc=9,column='Month',value=team['Date'].dt.month)\n",
    "    # chaning week datatype and removing any week larger than week 17\n",
    "    team['Week'] = team['Week'].astype(int)\n",
    "    team = team[team['Week']<=17]\n",
    "    team['Week'] = team['Week'].astype(str)\n",
    "    # saving cleaned data to csv\n",
    "    team.to_csv(f'../data/clean-data/nfl-team-data-{Season}-clean.csv',index=False)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f'Team data cleaned. {Season}',f'Time to complete: {end-start}',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine data\n",
    "def combine_season(Season):\n",
    "\n",
    "    # open csv files for combining data\n",
    "    inj = pd.read_csv(f'../data/clean-data/injury-report-{Season}-clean.csv')\n",
    "    stat = pd.read_csv(f'../data/clean-data/player-stats-{Season}-clean.csv')\n",
    "    snp = pd.read_csv(f'../data/clean-data/snap-counts-{Season}-clean.csv')\n",
    "    tm = pd.read_csv(f'../data/clean-data/nfl-team-data-{Season}-clean.csv')\n",
    "    \n",
    "    # combine stat and snap data\n",
    "    ss = pd.merge(left=stat,right=snp,how='outer',on=['Player','Season','Week'])\n",
    "    ss['Team_x'] = ss['Team_x'].fillna(ss['Team_y'])\n",
    "    ss['Pos_x'] = ss['Pos_y'].fillna(ss['Pos_x'])\n",
    "    ss.drop(['Team_y','Pos_y'], axis=1, inplace=True)\n",
    "    ss.rename(columns={'Team_x':'Team','Pos_x':'Pos'},inplace=True)\n",
    "    \n",
    "    # combine stat_snap data and injury data\n",
    "    ssj = pd.merge(left=ss,right=inj,how='outer',on=['Player','Season','Week'])\n",
    "    ssj['Date_x'] = ssj['Date_x'].fillna(ssj['Date_y'])\n",
    "    ssj['Team_x'] = ssj['Team_x'].fillna(ssj['Team_y'])\n",
    "    ssj['Opp_x'] = ssj['Opp_x'].fillna(ssj['Opp_y'])\n",
    "    ssj.drop(['Date_y','Team_y','Opp_y','Games'],axis=1,inplace=True)\n",
    "    ssj.rename(columns={'Date_x':'Date','Team_x':'Team','Opp_x':'Opp'},inplace=True)\n",
    "    ssj['Player'] = ssj['Player'].str.replace('.','')\n",
    "    ssj.dropna(subset=['Player'],inplace=True)\n",
    "    ssj['Week'] = ssj['Week'].astype(int)\n",
    "    player = ssj['Player'].unique().tolist()\n",
    "    player = player*17\n",
    "    player.sort()\n",
    "    df2 = pd.DataFrame(player,columns=['Player'])\n",
    "    df2['Season'] = Season\n",
    "    df2['Week'] = df2.groupby('Player').cumcount()+1\n",
    "    ssj = pd.merge(left=ssj, right=df2, how='outer', left_on=['Player', 'Season', 'Week'], right_on=['Player', 'Season', 'Week'])\n",
    "\n",
    "    # combine team data into the individual data to fill in some blanks\n",
    "    team = tm['Team'].unique().tolist()\n",
    "    team = team*17\n",
    "    team.sort()\n",
    "    team_df = pd.DataFrame(team, columns=['Team'])\n",
    "    team_df['Season'] = Season\n",
    "    team_df['Opp'] = \"Bye\"\n",
    "    team_df['Week'] = team_df.groupby('Team').cumcount()+1\n",
    "    tm = pd.merge(left=tm, right=team_df, how=\"outer\", on=['Team', 'Season', 'Week'])\n",
    "    tm['Opp_x'] = tm['Opp_x'].fillna(tm['Opp_y'])\n",
    "    tm.rename(columns={'Opp_x':'Opp'}, inplace=True)\n",
    "    tm.drop('Opp_y', axis=1, inplace=True)\n",
    "    \n",
    "\"\"\"\n",
    "Not merging properly because there is no \"Team\" value in \"Team\" column when merging below\n",
    "\"\"\"\n",
    "\n",
    "    ssjt = pd.merge(left=ssj, right=tm, how='outer', left_on=['Team', 'Week'], right_on=['Team', 'Week'])\n",
    "    return ssjt.sort_values(['Player', 'Week']).head(100)\n",
    "#     ssjt['Date_x'] = ssjt['Date_x'].fillna(ssjt['Date_y'])\n",
    "#     ssjt['Away_Home_x'] = ssjt['Away_Home_x'].fillna(ssjt['Away_Home_y'])\n",
    "#     ssjt['Opp_x'] = ssjt['Opp_x'].fillna(ssjt['Opp_y'])\n",
    "#     ssjt['G#_x'] = ssjt['G#_x'].fillna(ssjt['G#_y'])\n",
    "#     ssjt['Day_x'] = ssjt['Day_x'].fillna(ssjt['Day_y'])\n",
    "#     ssjt['Result_x'] = ssjt['Result_x'].fillna(ssjt['Result_y'])\n",
    "#     ssjt.drop(['Date_y','Away_Home_y','Opp_y','G#_y','Day_y','Result_y'],axis=1,inplace=True)\n",
    "#     ssjt.rename(columns={'Date_x':'Date','Away_Home_x':'Away_Home','Opp_x':'Opp','G#_x':'G#','Day_x':'Day','Result_x':'Result'},inplace=True)\n",
    "    \n",
    "#      # sort columns for easier viewing\n",
    "#     ssjt.sort_values(by=['Player','Week'],inplace=True)\n",
    "    \n",
    "#     # give/change all player positions to players with positions listed for the current year\n",
    "#     ssjt.replace({'Pos':{'0':None}},inplace=True)\n",
    "#     key = ssjt[['Player','Pos']]\n",
    "#     key = key.drop_duplicates()\n",
    "#     key = key.dropna()\n",
    "#     key.replace({'Pos':{'DT':'DL','CB':'DB','FB':'RB','OLB':'LB','S':'DB','G':'OL','DE':'DL','FS':'DB','RT':'OL','T':'OL','RG':'OL','LT':'OL','C':'OL','LS':'LongSnap','LDE':'DL','RILB':'LB','LCB':'DB','ILB':'LB',\\\n",
    "#                        'MLB':'LB','TB':'RB','LDT':'DL','NT':'DL','WILL':'LB','SS':'DB','RDE':'DL','SAM':'LB','HB':'RB','WR/RS':'WR','G/T':'OL','C/G':'OL','G/C':'OL','OT':'OL','CB/RS':'DB','DB/LB':'LB','T/G':'OL',\\\n",
    "#                         'RB/WR':'RB','LB/FB':'LB','DE/LB':'LB','DT/DE':'DL','TE/DE':'TE','K/P':'K','OS':'OL','LG':'OL','MIKE':'LB','LILB':'LB','WLB':'LB','G/OT':'OL','SLB':'LB','RCB':'DB'}},inplace=True)\n",
    "#     ssjt = pd.merge(ssjt,key,how='left',left_on='Player',right_on='Player')\n",
    "#     ssjt['Pos_x'] = ssjt['Pos_y']\n",
    "#     ssjt.drop(['Pos_y'],axis=1,inplace=True)\n",
    "#     ssjt.rename(columns={'Pos_x':'Pos'},inplace=True)\n",
    "#     ssjt['Injury'] = ssjt['Injury'].str.lower()\n",
    "#     ssjt['Injury'] = ssjt['Injury'].str.strip()\n",
    "#     ssjt.replace({'Injury':\n",
    "#                          {'biceps':'bicep','abdominal':'abdomen','core':'abdomen',\"broken fibula\":'fibula','fractured forearm':'forearm',\\\n",
    "#                           'general medical issue':'illness','quadriceps':'quadricep','ribs':'rib','rib cage':'rib','glute':'hip',\\\n",
    "#                           'sprained shoulder':'sprained ac joint','thumb sprain':'thumb','nack':'neck','nack, groin':'neck, groin',\\\n",
    "#                           'torn acl':'acl','torn mcl':'mcl','oblique':'abdomen'}},inplace=True)\n",
    "\n",
    "    # write data frame to csv\n",
    "#     ssjt.to_csv(f'../data/clean-data/nfl-{Season}.csv',index=False)\n",
    "\n",
    "def combine_all_season(Start,End):\n",
    "    start = time.time()\n",
    "    for yr in range(Start,End+1):\n",
    "        combine_season(yr)\n",
    "    end = time.time()\n",
    "    print(f'Data clean combined and cleaned further.',f'Time to complete: {end-start}',sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5 - Dash App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Create UI From Dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_app(Start,End):\n",
    "    inj = pd.DataFrame()\n",
    "    heal = pd.DataFrame()\n",
    "\n",
    "    for s in range(Start,End+1):\n",
    "        i= pd.read_csv(f'../data/analysis-data/injury-db-{s}.csv',low_memory=False)\n",
    "        h = pd.read_csv(f'../data/analysis-data/healthy-db-{s}.csv',low_memory=False)\n",
    "        i['Date'] = pd.to_datetime(i['Date'],format='%Y-%m-%d')\n",
    "        h['Date'] = pd.to_datetime(h['Date'],format='%Y-%m-%d')\n",
    "        inj = pd.concat([inj,i])\n",
    "        heal = pd.concat([heal,h])\n",
    "\n",
    "    inj = inj[['Player','Pos','Team','Season','Fntsy_Pts','Snaps','Status','Injury','Inj_Week']]\n",
    "    inj = inj.query(\"Snaps >= 20 and Pos == 'RB'\")\n",
    "    # df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    inj = pd.pivot_table(inj,index=['Season','Injury'])\n",
    "    inj.reset_index(inplace=True)\n",
    "    inj.sort_values(\"Injury\",inplace=True)\n",
    "\n",
    "    heal = heal[['Player','Pos','Team','Season','Fntsy_Pts','Snaps','Healthy_Week']]\n",
    "    heal = heal.query(\"Snaps >= 20 and Pos == 'RB'\")\n",
    "    # df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "    heal = pd.pivot_table(heal,index=['Season','Player'])\n",
    "    heal.reset_index(inplace=True)\n",
    "    heal.sort_values(\"Fntsy_Pts\",ascending=False,inplace=True)\n",
    "\n",
    "    app = JupyterDash(__name__)\n",
    "#     app.layout = html.Div([\n",
    "#             dash_table.DataTable(\n",
    "#                 id='heal_table',\n",
    "#                 columns=[{\n",
    "#                     'name':i,\n",
    "#                     'id':i,\n",
    "#                     'type':'numeric',\n",
    "#                     'format':Format(\n",
    "#                         scheme=Scheme.fixed,\n",
    "#                         precision=2,\n",
    "#                         decimal_delimiter='.',\n",
    "#                         trim=Trim.yes),\n",
    "#                     'selectable': True\n",
    "#                 } for i in heal.columns],\n",
    "#                 sort_mode = \"multi\",\n",
    "#                 sort_action = \"native\",\n",
    "#                 data=heal.to_dict('records'),\n",
    "#                 style_as_list_view = True,\n",
    "#                 style_cell = {\n",
    "#                     'padding':'5px',\n",
    "#                     'minWidth':'95px'\n",
    "#                 },\n",
    "#                 style_header = {\n",
    "#                     'backgroundColor':'#bababa',\n",
    "#                     'fontWeight':'bold'\n",
    "#                 },\n",
    "#                 style_cell_conditional = [\n",
    "#                     {\n",
    "#                         'if':{'column_id':c},\n",
    "#                         'textAlign':'left'\n",
    "#                     } for c in heal.columns\n",
    "#                 ],\n",
    "#                 style_data_conditional = (\n",
    "#                     [\n",
    "#                         {\n",
    "#                             'if':{\n",
    "#                                 'row_index':'odd'\n",
    "#                             },\n",
    "#                             'backgroundColor':'#f5f5f5'\n",
    "#                         }\n",
    "#                     ] + \n",
    "#                     [\n",
    "#                         {\n",
    "#                             'if':{\n",
    "#                                 'filter_query':'{{Fntsy_Pts}} = {}'.format(i),\n",
    "#                                 'column_id' : 'Fntsy_Pts'\n",
    "#                             },\n",
    "#                             'backgroundColor':'#14de1b'\n",
    "#                         }\n",
    "#                         for i in heal['Fntsy_Pts'].nlargest(5)\n",
    "#                     ] +\n",
    "#                     [\n",
    "#                         {\n",
    "#                             'if':{\n",
    "#                                 'filter_query':'{{{}}} <= {}'.format(col,val),\n",
    "#                                 'column_id': col\n",
    "#                             },\n",
    "#                             'backgroundColor':'red',\n",
    "#                             'color':'white'\n",
    "#                         }\n",
    "#                         for (col,val) in heal.quantile(0.1).iteritems()\n",
    "#                     ]\n",
    "#                 ),\n",
    "#                 fixed_rows = {'headers':True},\n",
    "#                 fixed_columns = {'headers':True,'data':1},\n",
    "#                 style_table = {\n",
    "#                     'height': 300,\n",
    "#                     'overflowY':'auto',\n",
    "#                     'overflowX':'auto',\n",
    "#                     'minWidth':'100%'\n",
    "#                 },\n",
    "#                 page_size = 25,\n",
    "#                 page_action = \"native\",\n",
    "#                 page_current = 0,\n",
    "#             ),\n",
    "#             html.Div(id='datatable-interactivity-container')])\n",
    "#     app.layout = html.Div([\n",
    "#             dash_table.DataTable(\n",
    "#                 id='inj_table',\n",
    "#                 columns=[{\n",
    "#                     'name':i,\n",
    "#                     'id':i,\n",
    "#                     'type':'numeric',\n",
    "#                     'format':Format(\n",
    "#                         scheme=Scheme.fixed,\n",
    "#                         precision=2,\n",
    "#                         decimal_delimiter='.',\n",
    "#                         trim=Trim.yes),\n",
    "#                     'selectable': True\n",
    "#                 } for i in inj.columns],\n",
    "#                 sort_mode = \"multi\",\n",
    "#                 sort_action = \"native\",\n",
    "#                 data=inj.to_dict('records'),\n",
    "#                 style_as_list_view = True,\n",
    "#                 style_cell = {\n",
    "#                     'padding':'5px',\n",
    "#                     'minWidth':'95px'\n",
    "#                 },\n",
    "#                 style_header = {\n",
    "#                     'backgroundColor':'#bababa',\n",
    "#                     'fontWeight':'bold'\n",
    "#                 },\n",
    "#                 style_cell_conditional = [\n",
    "#                     {\n",
    "#                         'if':{'column_id':c},\n",
    "#                         'textAlign':'left'\n",
    "#                     } for c in inj.columns\n",
    "#                 ],\n",
    "#                 style_data_conditional = (\n",
    "#                     [\n",
    "#                         {\n",
    "#                             'if':{\n",
    "#                                 'row_index':'odd'\n",
    "#                             },\n",
    "#                             'backgroundColor':'#f5f5f5'\n",
    "#                         }\n",
    "#                     ] + \n",
    "#                     [\n",
    "#                         {\n",
    "#                             'if':{\n",
    "#                                 'filter_query':'{{Fntsy_Pts}} = {}'.format(i),\n",
    "#                                 'column_id' : 'Fntsy_Pts'\n",
    "#                             },\n",
    "#                             'backgroundColor':'#14de1b'\n",
    "#                         }\n",
    "#                         for i in inj['Fntsy_Pts'].nlargest(5)\n",
    "#                     ] +\n",
    "#                     [\n",
    "#                         {\n",
    "#                             'if':{\n",
    "#                                 'filter_query':'{{{}}} <= {}'.format(col,val),\n",
    "#                                 'column_id': col\n",
    "#                             },\n",
    "#                             'backgroundColor':'red',\n",
    "#                             'color':'white'\n",
    "#                         }\n",
    "#                         for (col,val) in inj.quantile(0.1).iteritems()\n",
    "#                     ]\n",
    "#                 ),\n",
    "#                 fixed_rows = {'headers':True},\n",
    "#                 fixed_columns = {'headers':True,'data':1},\n",
    "#                 style_table = {\n",
    "#                     'height': 300,\n",
    "#                     'overflowY':'auto',\n",
    "#                     'overflowX':'auto',\n",
    "#                     'minWidth':'100%'\n",
    "#                 },\n",
    "#                 page_size = 25,\n",
    "#                 page_action = \"native\",\n",
    "#                 page_current = 0,\n",
    "#             ),\n",
    "#             html.Div(id='datatable-interactivity-container')])\n",
    "    app.run_server(mode='inline')#,port=8060)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fantasy_socre(2016,2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_app(2020,2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Start = 2016\n",
    "End = 2020\n",
    "inj = pd.DataFrame()\n",
    "heal = pd.DataFrame()\n",
    "\n",
    "for s in range(Start,End+1):\n",
    "    i= pd.read_csv(f'../data/analysis-data/injury-db-{s}.csv',low_memory=False)\n",
    "    h = pd.read_csv(f'../data/analysis-data/healthy-db-{s}.csv',low_memory=False)\n",
    "    i['Date'] = pd.to_datetime(i['Date'],format='%Y-%m-%d')\n",
    "    h['Date'] = pd.to_datetime(h['Date'],format='%Y-%m-%d')\n",
    "    inj = pd.concat([inj,i])\n",
    "    heal = pd.concat([heal,h])\n",
    "inj['Fntsy_Pts'] = ((inj['IPass_Yds'] * (1/25)) +\n",
    "                        (inj['IPass_TD'] * 4) +\n",
    "                        (inj['IPass_Int'] * -2) +\n",
    "                        (inj['IRush_Yds'] * (1/10)) +\n",
    "                        (inj['IRush_TD'] * 6) +\n",
    "                        (inj['IRec_Yds'] * (1/10)) +\n",
    "                        (inj['IRec_TD'] * 6) +\n",
    "                        (inj['IRec_Rec'] * 0.5) +\n",
    "                        (inj['I2pt_Made'] * 2) +\n",
    "                        (inj['IFmb_Lost'] * -2) +\n",
    "                        (inj['IKR_TD'] * 6) +\n",
    "                        (inj['IPR_TD'] * 6) +\n",
    "                        (inj['ITack_Sk'] * 3) +\n",
    "                        (inj['ITack_Solo'] * 1) +\n",
    "                        (inj['ITack_Ast'] * 0.5) +\n",
    "                        (inj['ITack_TFL'] * 1.5) +\n",
    "                        (inj['IDef_Int'] * 3) +\n",
    "                        (inj['IFmb_Forced'] * 3) +\n",
    "                        (inj['IFmb_Recov'] * 3) +\n",
    "                        ((inj['ITot_TD'] -\n",
    "                          inj['IPass_TD'] -\n",
    "                          inj['IRush_TD'] -\n",
    "                          inj['IRec_TD'] -\n",
    "                          inj['IKR_TD'] -\n",
    "                          inj['IPR_TD']) * 6) +\n",
    "                        (inj['ISfty'] * 2) +\n",
    "                        (inj['IDef_PD'] * 3))\n",
    "\n",
    "heal['Fntsy_Pts'] = ((heal['IPass_Yds'] * (1/25)) +\n",
    "                        (heal['IPass_TD'] * 4) +\n",
    "                        (heal['IPass_Int'] * -2) +\n",
    "                        (heal['IRush_Yds'] * (1/10)) +\n",
    "                        (heal['IRush_TD'] * 6) +\n",
    "                        (heal['IRec_Yds'] * (1/10)) +\n",
    "                        (heal['IRec_TD'] * 6) +\n",
    "                        (heal['IRec_Rec'] * 0.5) +\n",
    "                        (heal['I2pt_Made'] * 2) +\n",
    "                        (heal['IFmb_Lost'] * -2) +\n",
    "                        (heal['IKR_TD'] * 6) +\n",
    "                        (heal['IPR_TD'] * 6) +\n",
    "                        (heal['ITack_Sk'] * 3) +\n",
    "                        (heal['ITack_Solo'] * 1) +\n",
    "                        (heal['ITack_Ast'] * 0.5) +\n",
    "                        (heal['ITack_TFL'] * 1.5) +\n",
    "                        (heal['IDef_Int'] * 3) +\n",
    "                        (heal['IFmb_Forced'] * 3) +\n",
    "                        (heal['IFmb_Recov'] * 3) +\n",
    "                        ((heal['ITot_TD'] -\n",
    "                          heal['IPass_TD'] -\n",
    "                          heal['IRush_TD'] -\n",
    "                          heal['IRec_TD'] -\n",
    "                          heal['IKR_TD'] -\n",
    "                          heal['IPR_TD']) * 6) +\n",
    "                        (heal['ISfty'] * 2) +\n",
    "                        (heal['IDef_PD'] * 3))\n",
    "\n",
    "data = pd.concat([inj,heal])\n",
    "data = data[['Player','Pos','Team','Season','Week','Fntsy_Pts','Snaps','Status','Injury','Inj_Week','Healthy_Week']]\n",
    "\n",
    "inj = inj[['Player','Pos','Team','Season','Week','Fntsy_Pts','Snaps','Status','Injury','Inj_Week']]\n",
    "heal = heal[['Player','Pos','Team','Season','Week','Fntsy_Pts','Snaps','Healthy_Week']]\n",
    "\n",
    "piv_inj = pd.pivot_table(inj,index=['Season','Injury'])\n",
    "piv_inj.reset_index(inplace=True)\n",
    "piv_inj.sort_values(\"Injury\",inplace=True)\n",
    "\n",
    "piv_heal = pd.pivot_table(heal,index=['Season','Player'])\n",
    "piv_heal.reset_index(inplace=True)\n",
    "piv_heal.sort_values(\"Fntsy_Pts\",ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values('Fntsy_Pts',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
