{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4fc1845-7b79-4e42-9a0c-b1c7cff1bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import date, timedelta\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d193ad5a-fe8f-4f17-b16c-c241f332b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 2020\n",
    "players = pd.read_csv('../data/database-players.csv')\n",
    "players = players[players['Last_Year'] >= s]\n",
    "nfl_weeks = pd.read_csv('../data/NFL-Week-Dates.csv')\n",
    "nfl_weeks['Week'] = nfl_weeks['Week'].astype(str)\n",
    "def pre_thu(d):\n",
    "    days_behind = 3 - d.weekday()\n",
    "    if days_behind > 0:\n",
    "        days_behind -= 7\n",
    "    return d + dt.timedelta(days_behind)\n",
    "def findnth(haystack, needle, n):\n",
    "    parts= haystack.split(needle, n+1)\n",
    "    if len(parts)<=n+1:\n",
    "        return -1\n",
    "    return len(haystack)-len(parts[-1])-len(needle)\n",
    "def renaming_cols(col):\n",
    "    if \"Unnamed:\" in col:\n",
    "        new = col[findnth(col, \"'\", 2)+1:-2]\n",
    "    elif \"Passing\" in col or \"Rushing\" in col or \"Receiving\" in col or \"Fumbles\" in col or \"Scoring\" in col or \"Tackles\" in col or \"Punting\" in col:\n",
    "        new = col[findnth(col, \"'\", 0)+1:findnth(col, \"'\", 1)] + \"_\" + col[findnth(col, \"'\", 2)+1:findnth(col, \"'\", 3)]\n",
    "    elif \"Punt Returns\" in col or \"ST Snaps\" in col or \"Kick Returns\" in col:\n",
    "        new = col[findnth(col, \"'\", 0)+1:findnth(col, \" \", 0)] + \"_\" + col[findnth(col, \" \", 0)+1:findnth(col, \"'\", 1)] + \"_\" + col[findnth(col, \"'\", 2)+1:findnth(col, \"'\", 3)]\n",
    "    elif \"Def. Snaps\" in col or \"Off. Snaps\" in col:\n",
    "        new = col[findnth(col, \"'\", 0)+1:findnth(col, \" \", 0)-1] + \"_\" + col[findnth(col, \" \", 0)+1:findnth(col, \"'\", 1)] + \"_\" + col[findnth(col, \"'\", 2)+1:findnth(col, \"'\", 3)]\n",
    "    elif \"Def Interceptions\" in col:\n",
    "        new = col[findnth(col, \"'\", 0)+1:findnth(col, \" \", 0)] + \"_\" + col[findnth(col, \" \", 0)+1:findnth(col, \" \", 0)+4] + \"_\" + col[findnth(col, \"'\", 2)+1:findnth(col, \"'\", 3)]\n",
    "    else:\n",
    "        new = col\n",
    "    return new\n",
    "def player_address_rename(col):\n",
    "    if \"Player_Address\" in col:\n",
    "        new = col[:len(\"Player_Address\")]\n",
    "    else:\n",
    "        new = col\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c29ec65-2bfc-42e3-9a95-aea0e1209f65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# player stats clean\n",
    "start = time.time()\n",
    "stats = pd.read_csv(f'../data/raw-data/player-weekly-stats-{s}-raw.csv', low_memory=False)\n",
    "cols = []\n",
    "for c in stats.columns:\n",
    "    cols.append(c)\n",
    "cols.remove('Player_Address')\n",
    "cols.remove(\"('Unnamed: 3_level_0', 'Week')\")\n",
    "# stats = stats.groupby(['Player_Address', \"('Unnamed: 3_level_0', 'Week')\"])[cols].apply(lambda x: x.fillna(method=\"ffill\").fillna(method=\"bfill\").drop_duplicates()).reset_index\n",
    "stats = stats.rename(columns=renaming_cols)\n",
    "stats = stats.rename(columns = {\"Unnamed: 6_level_1\": \"Home_Away\", \"Tm\": \"Team\", \"Passing_Yds.1\": \"Passing_Sk_Yds\", \"GS\": \"Gm_Start\", \"G#\": \"Gm_Num\"})\n",
    "stats = pd.merge(left=stats, \n",
    "                 right=players, \n",
    "                 how='outer', \n",
    "                 left_on='Player_Address', \n",
    "                 right_on='Address')\n",
    "stats = stats.groupby(stats.columns, axis=1).sum()\n",
    "stats.drop(['First_Year', 'Last_Year', 'Rk', 'Address'], axis=1, inplace=True)\n",
    "stats.replace({'Home_Away': {'@': 'Away', 0: 'Home'}, \n",
    "               'Gm_Start': {'*': True, 0: False}}, inplace=True)\n",
    "stats.dropna(subset=['Player_Address'], inplace=True)\n",
    "stats[['Off_Snaps_Pct', \n",
    "       'Def_Snaps_Pct', \n",
    "       'ST_Snaps_Pct',\n",
    "       'Player_Address', \n",
    "       'Week']] = stats[['Off_Snaps_Pct', \n",
    "                         'Def_Snaps_Pct', \n",
    "                         'ST_Snaps_Pct', \n",
    "                         'Player_Address', \n",
    "                         'Week']].astype(str)\n",
    "stats['Off_Snaps_Pct'] = list(map(lambda x: x[:-1], stats['Off_Snaps_Pct'].values))\n",
    "stats['Def_Snaps_Pct'] = list(map(lambda x: x[:-1], stats['Def_Snaps_Pct'].values))\n",
    "stats['ST_Snaps_Pct'] = list(map(lambda x: x[:-1], stats['ST_Snaps_Pct'].values))\n",
    "stats['Player_Address'] = list(map(lambda x: x[11:], stats['Player_Address'].values))\n",
    "stats['Date'] = pd.to_datetime(stats['Date'], errors='coerce', format='%Y-%m-%d')\n",
    "stats = stats[['Player_Address', 'Player', 'Position', 'Age', \n",
    "               'Team', 'Home_Away', 'Opp', 'Result', 'Week', \n",
    "               'Gm_Num', 'Season', 'Gm_Start', 'Date', 'Off_Snaps_Num',\n",
    "               'Off_Snaps_Pct', 'Def_Snaps_Num', 'Def_Snaps_Pct',\n",
    "               'ST_Snaps_Num', 'ST_Snaps_Pct', 'Passing_Att',  'Passing_Cmp',\n",
    "               'Passing_Cmp%', 'Passing_Yds', 'Passing_TD', 'Passing_Int',\n",
    "               'Passing_Rate', 'Passing_Sk', 'Passing_Sk_Yds', 'Passing_Y/A',\n",
    "               'Passing_AY/A', 'Rushing_Att', 'Rushing_Yds', 'Rushing_Y/A',\n",
    "               'Rushing_TD', 'Receiving_Tgt', 'Receiving_Rec', 'Receiving_Yds', 'Receiving_TD',\n",
    "               'Receiving_Y/R', 'Receiving_Ctch%', 'Receiving_Y/Tgt', 'Kick_Returns_Rt',\n",
    "               'Kick_Returns_Yds', 'Kick_Returns_Y/Rt', 'Kick_Returns_TD', 'Punt_Returns_Ret', 'Punt_Returns_Yds',\n",
    "               'Punt_Returns_TD', 'Punt_Returns_Y/R', 'Punting_Pnt', 'Punting_Yds', 'Punting_Y/P',\n",
    "               'Punting_Blck', 'Scoring_TD', 'Scoring_Pts', 'Scoring_XPM',\n",
    "               'Scoring_XPA', 'Scoring_XP%', 'Scoring_FGM', 'Scoring_FGA',\n",
    "               'Scoring_FG%', 'Scoring_2PM', 'Scoring_Sfty', 'Sk',\n",
    "               'Tackles_Solo', 'Tackles_Ast', 'Tackles_Comb', 'Tackles_TFL',\n",
    "               'Tackles_QBHits', 'Def_Int_Int', 'Def_Int_Yds', 'Def_Int_TD',\n",
    "               'Def_Int_PD', 'Fumbles_Fmb', 'Fumbles_FL', 'Fumbles_FF',\n",
    "               'Fumbles_FR', 'Fumbles_Yds', 'Fumbles_TD']]\n",
    "for c in stats.columns[13:]:\n",
    "    stats[c] = pd.to_numeric(stats[c], errors='coerce')\n",
    "stats.to_csv(f'../data/clean-data/stats-{s}.csv', index=False)\n",
    "\n",
    "# player injurys clean\n",
    "injury = pd.read_csv(f'../data/raw-data/nfl-injury-report-{s}-raw.csv', low_memory=False)\n",
    "cols = [col for col in injury.columns if \"Player_Address\" in col]\n",
    "injury[\"Player_Address\"] = injury[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "injury = injury.drop(cols[1:], axis=1)\n",
    "injury = pd.melt(injury,\n",
    "                 id_vars=['Player', 'Team', 'Season', 'Player_Address'], \n",
    "                 var_name='Date', \n",
    "                 value_name='Status')\n",
    "injury[['Date','Opp']] = injury.Date.str.split('vs. ', expand=True)\n",
    "injury[['Month','Day']] = injury.Date.str.split('/', expand=True)\n",
    "injury[['Status','Injury']] = injury.Status.str.split(\":\", expand=True)\n",
    "injury.dropna(axis=0, subset=['Status','Injury'], how='all', inplace=True)\n",
    "injury[['Season', 'Month', 'Day']] = injury[['Season', 'Month', 'Day']].astype(int)\n",
    "injury['Date'] = injury['Date'] + '/' + (np.where(injury['Month'] <= 2, injury['Season'] + 1, injury['Season'])).astype(str)\n",
    "injury['Date'] = pd.to_datetime(injury['Date'])\n",
    "injury['week_start_nfl'] = injury['Date'].apply(pre_thu)\n",
    "nfl_weeks['Start Date'] = pd.to_datetime(nfl_weeks['Start Date'])\n",
    "injury = pd.merge(left=injury, \n",
    "                  right=nfl_weeks, \n",
    "                  how='left', \n",
    "                  left_on='week_start_nfl', \n",
    "                  right_on='Start Date')\n",
    "injury.replace({'Team':\n",
    "                   {'crd': 'ARI', 'atl': 'ATL', 'rav': 'BAL', 'buf': 'BUF', \n",
    "                    'car': 'CAR', 'chi': 'CHI', 'cin': 'CIN', 'cle': 'CLE', \n",
    "                    'dal': 'DAL', 'den': 'DEN', 'det': 'DET', 'gnb': 'GNB',\n",
    "                    'htx': 'HOU', 'clt': 'IND', 'jax': 'JAX', 'kan': 'KAN', \n",
    "                    'sdg': 'LAC', 'ram': 'LAR', 'mia': 'MIA', 'min': 'MIN', \n",
    "                    'nor': 'NOR', 'nwe': 'NWE', 'nyg': 'NYG', 'nyj': 'NYJ', \n",
    "                    'rai': 'OAK', 'phi': 'PHI', 'pit': 'PIT', 'sea': 'SEA',\n",
    "                    'sfo': 'SFO', 'tam': 'TAM', 'oti': 'TEN', 'was': 'WAS'}},\n",
    "               inplace=True)\n",
    "injury['Injury'] = injury['Injury'].str.strip(' ')\n",
    "injury.replace({\"Player_Address\": {\"_\": \"\", \"nan\": \"\"}}, regex=True, inplace=True)\n",
    "injury = pd.merge(left=injury,  \n",
    "                  right=players, \n",
    "                  how='outer', \n",
    "                  left_on='Player_Address',\n",
    "                  right_on='Address')\n",
    "injury.rename(columns={\"Player_x\": \"Player\"}, inplace=True)\n",
    "injury.drop(['Month', 'Day', 'week_start_nfl', 'Start Date', 'First_Year', 'Last_Year', 'Player_y'], axis=1, inplace=True)\n",
    "injury['Date'] = pd.to_datetime(injury['Date'], errors='coerce', format='%Y-%m-%d')\n",
    "injury.dropna(subset=['Player_Address'], inplace=True)\n",
    "injury.dropna(subset=['Week'], inplace=True)\n",
    "injury['Player_Address'] = list(map(lambda x: x[11:], injury['Player_Address'].values))\n",
    "injury = injury[[\"Player\", \"Team\", \"Season\", \"Player_Address\", \"Date\", \"Status\", \"Opp\", \"Injury\", \"Week\", \"Position\"]]\n",
    "injury.to_csv(f'../data/clean-data/injury-{s}.csv', index=False)\n",
    "\n",
    "# combine stats and injuries\n",
    "stats = pd.read_csv(f'../data/clean-data/stats-{s}.csv')\n",
    "injury = pd.read_csv(f'../data/clean-data/injury-{s}.csv')\n",
    "nfl_data = stats.merge(injury, \n",
    "                       how=\"outer\",\n",
    "                       on=[\"Player_Address\", \"Date\"])\n",
    "nfl_data[\"Player_x\"] = nfl_data[\"Player_x\"].fillna(nfl_data[\"Player_y\"])\n",
    "nfl_data[\"Position_x\"] = nfl_data[\"Position_x\"].fillna(nfl_data[\"Position_y\"])\n",
    "nfl_data[\"Team_x\"] = nfl_data[\"Team_x\"].fillna(nfl_data[\"Team_y\"])\n",
    "nfl_data[\"Opp_x\"] = nfl_data[\"Opp_x\"].fillna(nfl_data[\"Opp_y\"])\n",
    "nfl_data[\"Week_x\"] = nfl_data[\"Week_x\"].fillna(nfl_data[\"Week_y\"])\n",
    "nfl_data[\"Season_x\"] = nfl_data[\"Season_x\"].fillna(nfl_data[\"Season_y\"])\n",
    "nfl_data = nfl_data.rename(columns={\"Player_x\": \"Player\", \n",
    "                                    \"Position_x\": \"Position\", \n",
    "                                    \"Team_x\": \"Team\", \n",
    "                                    \"Opp_x\": \"Opp\", \n",
    "                                    \"Date_x\": \"Date\", \n",
    "                                    \"Season_x\": \"Season\", \n",
    "                                    \"Week_x\": \"Week\"})\n",
    "nfl_data = nfl_data[['Player_Address', 'Player', 'Position', 'Age', \n",
    "                     'Team', 'Home_Away', 'Opp', 'Result', 'Date', 'Week', \n",
    "                     'Gm_Num', 'Season', 'Status', 'Injury', 'Gm_Start', 'Off_Snaps_Num',\n",
    "                     'Off_Snaps_Pct', 'Def_Snaps_Num', 'Def_Snaps_Pct',\n",
    "                     'ST_Snaps_Num', 'ST_Snaps_Pct', 'Passing_Att',  'Passing_Cmp',\n",
    "                     'Passing_Cmp%', 'Passing_Yds', 'Passing_TD', 'Passing_Int',\n",
    "                     'Passing_Rate', 'Passing_Sk', 'Passing_Sk_Yds', 'Passing_Y/A',\n",
    "                     'Passing_AY/A', 'Rushing_Att', 'Rushing_Yds', 'Rushing_Y/A',\n",
    "                     'Rushing_TD', 'Receiving_Tgt', 'Receiving_Rec', 'Receiving_Yds', 'Receiving_TD',\n",
    "                     'Receiving_Y/R', 'Receiving_Ctch%', 'Receiving_Y/Tgt', 'Kick_Returns_Rt',\n",
    "                     'Kick_Returns_Yds', 'Kick_Returns_Y/Rt', 'Kick_Returns_TD', 'Punt_Returns_Ret', 'Punt_Returns_Yds',\n",
    "                     'Punt_Returns_TD', 'Punt_Returns_Y/R', 'Punting_Pnt', 'Punting_Yds', 'Punting_Y/P',\n",
    "                     'Punting_Blck', 'Scoring_TD', 'Scoring_Pts', 'Scoring_XPM',\n",
    "                     'Scoring_XPA', 'Scoring_XP%', 'Scoring_FGM', 'Scoring_FGA',\n",
    "                     'Scoring_FG%', 'Scoring_2PM', 'Scoring_Sfty', 'Sk',\n",
    "                     'Tackles_Solo', 'Tackles_Ast', 'Tackles_Comb', 'Tackles_TFL',\n",
    "                     'Tackles_QBHits', 'Def_Int_Int', 'Def_Int_Yds', 'Def_Int_TD',\n",
    "                     'Def_Int_PD', 'Fumbles_Fmb', 'Fumbles_FL', 'Fumbles_FF',\n",
    "                     'Fumbles_FR', 'Fumbles_Yds', 'Fumbles_TD']]\n",
    "nfl_data.to_csv(f'../data/clean-data/nfl-{s}.csv', index=False)\n",
    "\n",
    "# create a database of all athletes that sustained an injury and what their production was post injury for the remainder of the season\n",
    "\n",
    "nfl_data = pd.read_csv(f'../data/clean-data/nfl-{s}.csv', low_memory=False)\n",
    "nfl_data.sort_values(['Player_Address','Week'], inplace=True)\n",
    "nfl_data.reset_index(inplace=True)\n",
    "nfl_data.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "status = nfl_data['Status'].dropna().unique().tolist()\n",
    "player_list = nfl_data.loc[nfl_data['Status'].isin(status)].drop_duplicates(subset=['Player_Address']).index.unique().tolist()\n",
    "\n",
    "injury_weeks = pd.DataFrame()\n",
    "healthy_weeks = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(player_list)):\n",
    "    idx = nfl_data[nfl_data['Player_Address'] == nfl_data['Player_Address'][player_list[i]]].tail(1)\n",
    "    inj = nfl_data.loc[player_list[i]-1: idx.index.values.astype(int)[0]]\n",
    "    injury_weeks = pd.concat([injury_weeks, inj])\n",
    "injury_weeks['Inj_Week'] = 0\n",
    "injury_weeks['Inj_Week'] = injury_weeks.groupby('Player_Address').cumcount()\n",
    "\n",
    "for i in range(0,len(player_list)):\n",
    "    idx = nfl_data[nfl_data['Player_Address'] == nfl_data['Player_Address'][player_list[i]]].head(1)\n",
    "    healthy = nfl_data.loc[idx.index.values.astype(int)[0]:player_list[i]-1]\n",
    "    healthy_weeks = pd.concat([healthy_weeks, healthy])\n",
    "healthy_weeks['Healthy_Week'] = 0\n",
    "healthy_weeks['Healthy_Week'] = healthy_weeks.groupby('Player_Address').cumcount()+1\n",
    "\n",
    "injury_weeks.to_csv(f'../data/clean-data/weeks-injured-{s}.csv', index=False)\n",
    "healthy_weeks.to_csv(f'../data/clean-data/weeks-healthy-{s}.csv', index=False)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(f'Done with season {s}. Time to complete: {end-start} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2903961-386e-431c-983d-420d886e278d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s = 2020\n",
    "# i = pd.read_csv(f'../data/clean-data/weeks-injured-{s}.csv')\n",
    "# h = pd.read_csv(f'../data/clean-data/weeks-healthy-{s}.csv')\n",
    "# c = i.merge(h, how=\"outer\", on=['Player_Address', 'Player', 'Position', 'Age', 'Team', 'Home_Away',\n",
    "#        'Opp', 'Result', 'Date', 'Week', 'Gm_Num', 'Season', \n",
    "#        'Gm_Start', 'Off_Snaps_Num', 'Off_Snaps_Pct', 'Def_Snaps_Num',\n",
    "#        'Def_Snaps_Pct', 'ST_Snaps_Num', 'ST_Snaps_Pct', 'Passing_Att',\n",
    "#        'Passing_Cmp', 'Passing_Cmp%', 'Passing_Yds', 'Passing_TD',\n",
    "#        'Passing_Int', 'Passing_Rate', 'Passing_Sk', 'Passing_Sk_Yds',\n",
    "#        'Passing_Y/A', 'Passing_AY/A', 'Rushing_Att', 'Rushing_Yds',\n",
    "#        'Rushing_Y/A', 'Rushing_TD', 'Receiving_Tgt', 'Receiving_Rec',\n",
    "#        'Receiving_Yds', 'Receiving_TD', 'Receiving_Y/R', 'Receiving_Ctch%',\n",
    "#        'Receiving_Y/Tgt', 'Kick_Returns_Rt', 'Kick_Returns_Yds',\n",
    "#        'Kick_Returns_Y/Rt', 'Kick_Returns_TD', 'Punt_Returns_Ret',\n",
    "#        'Punt_Returns_Yds', 'Punt_Returns_TD', 'Punt_Returns_Y/R',\n",
    "#        'Punting_Pnt', 'Punting_Yds', 'Punting_Y/P', 'Punting_Blck',\n",
    "#        'Scoring_TD', 'Scoring_Pts', 'Scoring_XPM', 'Scoring_XPA',\n",
    "#        'Scoring_XP%', 'Scoring_FGM', 'Scoring_FGA', 'Scoring_FG%',\n",
    "#        'Scoring_2PM', 'Scoring_Sfty', 'Sk', 'Tackles_Solo', 'Tackles_Ast',\n",
    "#        'Tackles_Comb', 'Tackles_TFL', 'Tackles_QBHits', 'Def_Int_Int',\n",
    "#        'Def_Int_Yds', 'Def_Int_TD', 'Def_Int_PD', 'Fumbles_Fmb', 'Fumbles_FL',\n",
    "#        'Fumbles_FF', 'Fumbles_FR', 'Fumbles_Yds', 'Fumbles_TD'])\n",
    "# c['Status_x'] = c['Status_x'].fillna(c['Status_y'])\n",
    "# c['Injury_x'] = c['Injury_x'].fillna(c['Injury_y'])\n",
    "# c.rename(columns={'Status_x': 'Status',\n",
    "#                   'Injury_x': 'Injury'},\n",
    "#         inplace=True)\n",
    "# c.drop(['Injury_y','Status_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a2318b6-f74c-4586-83b1-44396d140f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ab91a-e6db-4425-8863-19b19df354f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for c in test.columns:\n",
    "    cols.append(c)\n",
    "cols.remove('Player_Address')\n",
    "cols.remove('Week')\n",
    "t = test.groupby(['Player_Address', 'Week'])[cols].apply(lambda x: x.ffill().bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3359f0e-3030-449f-ab43-2d6a16b155a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:,cols] = t.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0585b-b315-4279-9dd6-c810643a3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e5b62-0639-47db-9ef4-080b17a64339",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251ae8e-d41f-47bb-8fba-660f2e37a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = test[test.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc65bc10-c5d5-441a-88f0-9b42444adbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3364f586-84d9-46a4-9d17-0710ceab3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups.to_csv('dups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0da58-0a37-4c80-9c86-e5cf1b278b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
