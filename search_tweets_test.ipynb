{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json, yaml, os, time\n",
    "import pandas as pd\n",
    "from searchtweets import load_credentials, gen_rule_payload, ResultStream\n",
    "from tweet_parser.tweet import Tweet\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "query = '\"Joe Mixon\" \"Foot\" from:InsideInjuries OR from:ProFootballDoc OR from:AdamSchefter'\n",
    "\n",
    "results_per_call = 100  # 100 for sandbox, 500 for paid tiers\n",
    "to_date = '2020-11-15' # format YYYY-MM-DD HH:MM (hour and minutes optional)\n",
    "from_date = '2020-11-1'  # format YYYY-MM-DD HH:MM (hour and minutes optional)\n",
    "\n",
    "# max number of tweets to collect\n",
    "max_results = 5\n",
    "\n",
    "# Script prints an update to the CLI every time it collected another X Tweets\n",
    "print_after = 5\n",
    "\n",
    "# opening the communication\n",
    "premium_search_args = load_credentials(\"twitter_keys.yaml\",yaml_key=\"search_tweets_api\", env_overwrite=False)\n",
    "\n",
    "# creating the payload for search\n",
    "rule = gen_rule_payload(query,results_per_call=results_per_call,from_date=from_date,to_date=to_date)\n",
    "\n",
    "#returning the results from the payload and stops at max_results\n",
    "rs = ResultStream(rule_payload=rule,max_results=max_results,**premium_search_args)\n",
    "\n",
    "# working properly, need to filter out retweets by using retweeted_status to remove retweets would be easiest in a dataframe\n",
    "# need to format it for a pandas DF and write into csv instead of writing the full dictionary\n",
    "# find headers within the data so that the differing size rows get split up properly\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# loop to open FILENAME as f and write to f the value of tweet which would be results_per_call\n",
    "for tweet in rs.stream():\n",
    "    df = pd.json_normalize(tweet)\n",
    "    final_df = pd.concat([final_df, df])\n",
    "final_df = final_df[['user.name','user.screen_name','quote_count','retweet_count','retweeted','text','extended_tweet.full_text','retweeted_status.user.screen_name','retweeted_status.text','quoted_status.user.screen_name','quoted_status.text']]\n",
    "#final_df.to_csv('injury_tweets.csv',index=False)\n",
    "print('done')\n",
    "final_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
